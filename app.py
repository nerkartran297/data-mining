import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import math
from sklearn.preprocessing import MinMaxScaler

# Import c√°c h√†m t·ª´ func.py
import func 

# C·∫•u h√¨nh trang Streamlit
st.set_page_config(
    layout="wide", 
    page_title="üîç Data Mining Toolkit", 
    page_icon="üîç",
    initial_sidebar_state="expanded"
)

# Custom CSS ƒë·ªÉ l√†m ƒë·∫πp giao di·ªán v√† support dark mode
st.markdown("""
<style>
    /* Main header - adaptable to theme */
    .main-header {
        font-size: 3rem;
        color: var(--text-color, #1f77b4);
        text-align: center;
        margin-bottom: 2rem;
    }
    
    /* Algorithm cards - always visible */
    .algorithm-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white !important;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    
    /* Info boxes - dark mode compatible */
    .info-box {
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 4px solid #2196F3;
        background-color: rgba(33, 150, 243, 0.1);
        color: inherit;
    }
    
    /* Explanation boxes */
    .explanation-box {
        background: rgba(76, 175, 80, 0.1);
        border-left: 4px solid #4CAF50;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        color: inherit;
    }
    
    /* Warning boxes */
    .warning-box {
        background: rgba(255, 193, 7, 0.1);
        border-left: 4px solid #FFC107;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        color: inherit;
    }
    
    /* Success boxes */
    .success-box {
        background: rgba(76, 175, 80, 0.1);
        border-left: 4px solid #4CAF50;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        color: inherit;
    }
    
    /* Error boxes */
    .error-box {
        background: rgba(244, 67, 54, 0.1);
        border-left: 4px solid #f44336;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        color: inherit;
    }
    
    /* Step-by-step explanation */
    .step-explanation {
        background: rgba(156, 39, 176, 0.1);
        border-left: 4px solid #9C27B0;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        color: inherit;
    }
    
    /* Variable explanation */
    .variable-explanation {
        background: rgba(255, 87, 34, 0.1);
        border-left: 4px solid #FF5722;
        padding: 12px;
        border-radius: 5px;
        margin: 8px 0;
        color: inherit;
        font-family: 'Courier New', monospace;
    }
    
    /* Formula display */
    .formula-box {
        background: rgba(63, 81, 181, 0.1);
        border: 2px solid #3F51B5;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        text-align: center;
        font-family: 'Times New Roman', serif;
        color: inherit;
    }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# HEADER & NAVIGATION
# ==============================================================================
st.markdown('<h1 class="main-header">üîç Data Mining Toolkit</h1>', unsafe_allow_html=True)

col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    st.markdown("""
    <div class="info-box" style="text-align: center; margin-bottom: 30px;">
        <h3>üéì ƒê·ªì √°n cu·ªëi k·ª≥: Khai th√°c D·ªØ li·ªáu</h3>
        <p><strong>üë®‚Äçüíª Nh√≥m th·ª±c hi·ªán:</strong> Tr·∫ßn Nh·∫≠t Kh√°nh & Tr·∫ßn Nh·∫≠t Huy</p>
        <p>üìö 6 thu·∫≠t to√°n Data Mining v·ªõi giao di·ªán th√¢n thi·ªán</p>
    </div>
    """, unsafe_allow_html=True)

# ==============================================================================
# SIDEBAR CONFIGURATION
# ==============================================================================
with st.sidebar:
    st.markdown("## üìÅ C·∫•u h√¨nh d·ªØ li·ªáu")
    
    # File upload with better styling
    uploaded_file = st.file_uploader(
        "üì§ Ch·ªçn file CSV ƒë·ªÉ ph√¢n t√≠ch", 
        type=["csv"],
        help="H·ªó tr·ª£ c√°c file CSV c√≥ c·∫•u tr√∫c d·ªØ li·ªáu ph√π h·ª£p"
    )
    
    # Load demo data option
    st.markdown("---")
    st.markdown("### üìä Ho·∫∑c s·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u")
    demo_options = {
        "Kh√¥ng s·ª≠ d·ª•ng": None,
        "üõí Apriori - Giao d·ªãch": "data_apriori.csv",
        "‚öñÔ∏è Rough Set - Ph√¢n lo·∫°i": "data_rough_set.csv", 
        "üå≥ Decision Tree - Tennis": "data_tree.csv",
        "üéØ Naive Bayes - Tennis": "data_nb.csv",
        "üé® Clustering - Art": "data_k-means_kohonen.csv"
    }
    
    demo_choice = st.selectbox("Ch·ªçn d·ªØ li·ªáu m·∫´u:", list(demo_options.keys()))
    
    if demo_choice != "Kh√¥ng s·ª≠ d·ª•ng" and demo_options[demo_choice]:
        try:
            uploaded_file = demo_options[demo_choice]
            st.success(f"‚úÖ ƒê√£ ch·ªçn: {demo_choice}")
        except:
            st.error("‚ùå Kh√¥ng t√¨m th·∫•y file m·∫´u")

# Load data
df_original = None
if uploaded_file is not None:
    try:
        if isinstance(uploaded_file, str):  # Demo file
            df_original = pd.read_csv(uploaded_file)
        else:  # Uploaded file
            df_original = pd.read_csv(uploaded_file)
        
        with st.sidebar:
            st.markdown("### üìã Th√¥ng tin d·ªØ li·ªáu")
            st.info(f"üìä K√≠ch th∆∞·ªõc: {df_original.shape[0]} h√†ng x {df_original.shape[1]} c·ªôt")
            st.info(f"üíæ B·ªô nh·ªõ: {df_original.memory_usage(deep=True).sum() / 1024:.1f} KB")
    except Exception as e:
        st.error(f"‚ùå L·ªói ƒë·ªçc file: {e}")
        df_original = None

# ==============================================================================
# MAIN CONTENT AREA
# ==============================================================================
if df_original is not None:
    # Data preview section
    with st.expander("üëÄ Xem tr∆∞·ªõc d·ªØ li·ªáu", expanded=True):
        col1, col2 = st.columns([3, 1])
        with col1:
            st.dataframe(df_original.head(10), use_container_width=True)
        with col2:
            st.markdown("### üìà Th·ªëng k√™ c∆° b·∫£n")
            st.metric("S·ªë d√≤ng", df_original.shape[0])
            st.metric("S·ªë c·ªôt", df_original.shape[1])
            st.metric("Gi√° tr·ªã null", df_original.isnull().sum().sum())
    
    # Algorithm selection with tabs
    st.markdown("## üõ†Ô∏è Ch·ªçn thu·∫≠t to√°n ph√¢n t√≠ch")
    
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üõí Apriori", "‚öñÔ∏è Rough Set", "üå≥ Decision Tree", 
        "üéØ Naive Bayes", "üë• K-Means", "üó∫Ô∏è SOM"
    ])
    
    # ==============================================================================
    # APRIORI TAB
    # ==============================================================================
    with tab1:
        st.markdown("### üõí Thu·∫≠t to√°n Apriori - T√¨m lu·∫≠t k·∫øt h·ª£p")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt thu·∫≠t to√°n Apriori", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>Apriori</strong> l√† thu·∫≠t to√°n kinh ƒëi·ªÉn ƒë·ªÉ t√¨m c√°c <strong>t·∫≠p m·ª•c ph·ªï bi·∫øn</strong> (frequent itemsets) 
                v√† <strong>lu·∫≠t k·∫øt h·ª£p</strong> (association rules) trong d·ªØ li·ªáu giao d·ªãch.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ i1, i2, i3, i4...</strong> = Item (s·∫£n ph·∫©m): ƒê·∫°i di·ªán cho c√°c s·∫£n ph·∫©m ri√™ng l·∫ª</p>
                <p><strong>‚Ä¢ T1, T2, T3...</strong> = Transaction (giao d·ªãch): M·ªói giao d·ªãch ch·ª©a nhi·ªÅu items</p>
                <p><strong>‚Ä¢ L1, L2, L3...</strong> = Level k itemsets: T·∫≠p ph·ªï bi·∫øn c√≥ k ph·∫ßn t·ª≠</p>
                <p><strong>‚Ä¢ C1, C2, C3...</strong> = Candidate itemsets: T·∫≠p ·ª©ng vi√™n c·∫ßn ki·ªÉm tra</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>Support(X) = |T(X)| / |D|</strong></p>
                <p>Trong ƒë√≥: T(X) = s·ªë giao d·ªãch ch·ª©a itemset X, D = t·ªïng s·ªë giao d·ªãch</p>
                <hr>
                <p><strong>Confidence(X ‚Üí Y) = Support(X ‚à™ Y) / Support(X)</strong></p>
                <p>ƒê·ªô tin c·∫≠y c·ªßa lu·∫≠t: X xu·∫•t hi·ªán th√¨ Y c≈©ng xu·∫•t hi·ªán</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> Qu√©t d·ªØ li·ªáu, ƒë·∫øm t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa t·ª´ng item ƒë∆°n l·∫ª</p>
                <p><strong>B∆∞·ªõc 2:</strong> Lo·∫°i b·ªè items c√≥ support < min_support ‚Üí T·∫°o L1</p>
                <p><strong>B∆∞·ªõc 3:</strong> T·∫°o t·∫≠p ·ª©ng vi√™n C2 t·ª´ L1 (k·∫øt h·ª£p 2 items)</p>
                <p><strong>B∆∞·ªõc 4:</strong> T√≠nh support cho C2, lo·∫°i b·ªè itemsets kh√¥ng ƒë·∫°t ‚Üí T·∫°o L2</p>
                <p><strong>B∆∞·ªõc 5:</strong> L·∫∑p l·∫°i cho ƒë·∫øn khi kh√¥ng t√¨m ƒë∆∞·ª£c t·∫≠p ph·ªï bi·∫øn m·ªõi</p>
                <p><strong>B∆∞·ªõc 6:</strong> Sinh lu·∫≠t k·∫øt h·ª£p t·ª´ c√°c t·∫≠p ph·ªï bi·∫øn</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ T√¨m c√°c t·∫≠p m·ª•c ph·ªï bi·∫øn</p>
                <p>‚Ä¢ Sinh lu·∫≠t k·∫øt h·ª£p</p>
                <p>‚Ä¢ ·ª®ng d·ª•ng: Market Basket Analysis</p>
                <p>‚Ä¢ Ph√¢n t√≠ch mua s·∫Øm kh√°ch h√†ng</p>
                <p>‚Ä¢ G·ª£i √Ω s·∫£n ph·∫©m</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_apriori_input = df_original.copy()
            df_apriori_input = df_apriori_input.loc[:, ~df_apriori_input.columns.str.startswith('Unnamed')]
            
            st.markdown("#### ‚öôÔ∏è C·∫•u h√¨nh ti·ªÅn x·ª≠ l√Ω")
            preprocess_method = st.radio(
                "Ch·ªçn ph∆∞∆°ng ph√°p x·ª≠ l√Ω d·ªØ li·ªáu:",
                ("üî¢ One-hot encode", "üìä S·ª≠ d·ª•ng d·ªØ li·ªáu s·ªë g·ªëc", "üîÑ Chuy·ªÉn ƒë·ªïi boolean"),
                horizontal=True
            )
            
            df_processed = None
            if "One-hot" in preprocess_method:
                cols_to_encode = st.multiselect(
                    "Ch·ªçn c·ªôt ƒë·ªÉ m√£ h√≥a:",
                    df_apriori_input.columns.tolist(),
                    help="Ch·ªçn c√°c c·ªôt categorical ƒë·ªÉ chuy·ªÉn th√†nh d·∫°ng binary"
                )
                if cols_to_encode:
                    df_processed = func.apriori_one_hot_encode_data(df_apriori_input, cols_to_encode)
            elif "s·ªë g·ªëc" in preprocess_method:
                df_processed = func.apriori_original_process_data(df_apriori_input)
            else:
                df_processed = func.apriori_general_transactional_conversion(df_apriori_input)
            
            if df_processed is not None:
                with st.expander("üëÄ Xem d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"):
                    st.dataframe(df_processed.head())
                
                st.markdown("#### üéöÔ∏è Thi·∫øt l·∫≠p tham s·ªë")
                col_a, col_b = st.columns(2)
                with col_a:
                    min_support = st.slider("üéØ Min Support", 0.01, 1.0, 0.3, 0.01, 
                                          help="Ng∆∞·ª°ng h·ªó tr·ª£ t·ªëi thi·ªÉu (0.3 = 30%)")
                with col_b:
                    min_confidence = st.slider("üí™ Min Confidence", 0.01, 1.0, 0.6, 0.01,
                                             help="Ng∆∞·ª°ng tin c·∫≠y t·ªëi thi·ªÉu (0.6 = 60%)")
                
                if st.button("üöÄ Ch·∫°y Apriori", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ ƒêang ph√¢n t√≠ch..."):
                        try:
                            f_itemsets, rules, max_f_itemsets = func.run_apriori_calculations(
                                df_processed, min_support, min_confidence
                            )
                            
                            st.markdown("### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                            
                            # Metrics row
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("üéØ T·∫≠p ph·ªï bi·∫øn", len(f_itemsets) if not f_itemsets.empty else 0)
                            with col2:
                                st.metric("‚≠ê T·∫≠p t·ªëi ƒë·∫°i", len(max_f_itemsets) if not max_f_itemsets.empty else 0)
                            with col3:
                                st.metric("üìú Lu·∫≠t k·∫øt h·ª£p", len(rules) if not rules.empty else 0)
                            
                            # Explanation of results
                            st.markdown("""
                            <div class="explanation-box">
                                <h4>üìñ Gi·∫£i th√≠ch k·∫øt qu·∫£:</h4>
                                <p><strong>‚Ä¢ T·∫≠p ph·ªï bi·∫øn:</strong> C√°c t·∫≠p items xu·∫•t hi·ªán c√πng nhau v·ªõi t·∫ßn su·∫•t ‚â• min_support</p>
                                <p><strong>‚Ä¢ T·∫≠p t·ªëi ƒë·∫°i:</strong> T·∫≠p ph·ªï bi·∫øn kh√¥ng l√† t·∫≠p con c·ªßa t·∫≠p ph·ªï bi·∫øn n√†o kh√°c</p>
                                <p><strong>‚Ä¢ Lu·∫≠t k·∫øt h·ª£p:</strong> Lu·∫≠t d·∫°ng "X ‚Üí Y" v·ªõi ƒë·ªô tin c·∫≠y ‚â• min_confidence</p>
                                <p><strong>‚Ä¢ Support:</strong> T·ª∑ l·ªá giao d·ªãch ch·ª©a itemset trong t·ªïng s·ªë giao d·ªãch</p>
                                <p><strong>‚Ä¢ Confidence:</strong> T·ª∑ l·ªá giao d·ªãch ch·ª©a Y trong s·ªë giao d·ªãch ch·ª©a X</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Results display
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("#### üéØ T·∫≠p ph·ªï bi·∫øn")
                                if not f_itemsets.empty:
                                    display_df = f_itemsets.copy()
                                    display_df['itemsets'] = display_df['itemsets'].apply(lambda x: ', '.join(list(x)))
                                    st.dataframe(display_df[['support', 'itemsets']], use_container_width=True)
                                else:
                                    st.info("Kh√¥ng t√¨m th·∫•y t·∫≠p ph·ªï bi·∫øn n√†o")
                            
                            with col2:
                                st.markdown("#### üìú Lu·∫≠t k·∫øt h·ª£p")
                                if not rules.empty:
                                    display_rules = rules.copy()
                                    display_rules['Rule'] = (display_rules['antecedents'].apply(lambda x: ', '.join(list(x))) + 
                                                           ' ‚Üí ' + 
                                                           display_rules['consequents'].apply(lambda x: ', '.join(list(x))))
                                    st.dataframe(display_rules[['Rule', 'confidence', 'support']], use_container_width=True)
                                else:
                                    st.info("Kh√¥ng t√¨m th·∫•y lu·∫≠t k·∫øt h·ª£p n√†o")
                            
                            # Detailed calculation explanation
                            with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                detailed_explanation = func.get_apriori_detailed_explanation(
                                    df_apriori_input, min_support, min_confidence
                                )
                                st.markdown(detailed_explanation)
                                    
                        except Exception as e:
                            st.error(f"‚ùå L·ªói: {e}")
    
    # ==============================================================================
    # ROUGH SET TAB
    # ==============================================================================
    with tab2:
        st.markdown("### ‚öñÔ∏è Thu·∫≠t to√°n Rough Set - L√Ω thuy·∫øt t·∫≠p th√¥")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt l√Ω thuy·∫øt Rough Set", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>Rough Set Theory</strong> ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Pawlak (1982) ƒë·ªÉ x·ª≠ l√Ω th√¥ng tin 
                kh√¥ng ch·∫Øc ch·∫Øn v√† kh√¥ng ƒë·∫ßy ƒë·ªß trong vi·ªác ph√¢n lo·∫°i d·ªØ li·ªáu.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ U</strong> = Universe (v≈© tr·ª•): T·∫≠p h·ª£p t·∫•t c·∫£ c√°c ƒë·ªëi t∆∞·ª£ng</p>
                <p><strong>‚Ä¢ A</strong> = Attributes (thu·ªôc t√≠nh): T·∫≠p thu·ªôc t√≠nh m√¥ t·∫£ ƒë·ªëi t∆∞·ª£ng</p>
                <p><strong>‚Ä¢ D</strong> = Decision attribute (thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh): Thu·ªôc t√≠nh ph√¢n lo·∫°i</p>
                <p><strong>‚Ä¢ [x]·µ£</strong> = Equivalence class: L·ªõp t∆∞∆°ng ƒë∆∞∆°ng c·ªßa ƒë·ªëi t∆∞·ª£ng x</p>
                <p><strong>‚Ä¢ R(X)</strong> = Lower approximation: X·∫•p x·ªâ d∆∞·ªõi c·ªßa t·∫≠p X</p>
                <p><strong>‚Ä¢ RÃÑ(X)</strong> = Upper approximation: X·∫•p x·ªâ tr√™n c·ªßa t·∫≠p X</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>Lower Approximation: R(X) = {x ‚àà U | [x]·µ£ ‚äÜ X}</strong></p>
                <p>C√°c ƒë·ªëi t∆∞·ª£ng ch·∫Øc ch·∫Øn thu·ªôc l·ªõp X</p>
                <hr>
                <p><strong>Upper Approximation: RÃÑ(X) = {x ‚àà U | [x]·µ£ ‚à© X ‚â† ‚àÖ}</strong></p>
                <p>C√°c ƒë·ªëi t∆∞·ª£ng c√≥ th·ªÉ thu·ªôc l·ªõp X</p>
                <hr>
                <p><strong>Accuracy: Œ±(X) = |R(X)| / |RÃÑ(X)|</strong></p>
                <p>ƒê·ªô ch√≠nh x√°c c·ªßa vi·ªác ph√¢n lo·∫°i t·∫≠p X</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> X√°c ƒë·ªãnh thu·ªôc t√≠nh ƒëi·ªÅu ki·ªán v√† thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh</p>
                <p><strong>B∆∞·ªõc 2:</strong> T·∫°o c√°c l·ªõp t∆∞∆°ng ƒë∆∞∆°ng d·ª±a tr√™n thu·ªôc t√≠nh ƒëi·ªÅu ki·ªán</p>
                <p><strong>B∆∞·ªõc 3:</strong> T√≠nh Lower Approximation (c√°c ƒë·ªëi t∆∞·ª£ng ch·∫Øc ch·∫Øn)</p>
                <p><strong>B∆∞·ªõc 4:</strong> T√≠nh Upper Approximation (c√°c ƒë·ªëi t∆∞·ª£ng c√≥ th·ªÉ)</p>
                <p><strong>B∆∞·ªõc 5:</strong> T√≠nh ƒë·ªô ch√≠nh x√°c v√† m·ª©c ƒë·ªô ph·ª• thu·ªôc</p>
                <p><strong>B∆∞·ªõc 6:</strong> T√¨m c√°c Reduct (t·∫≠p thu·ªôc t√≠nh t·ªëi thi·ªÉu)</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ X·ª≠ l√Ω uncertainty trong d·ªØ li·ªáu</p>
                <p>‚Ä¢ T√¨m attribute reducts</p>
                <p>‚Ä¢ Lower/Upper approximation</p>
                <p>‚Ä¢ Gi·∫£m chi·ªÅu d·ªØ li·ªáu</p>
                <p>‚Ä¢ Feature selection t·ª± ƒë·ªông</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_rs_input = df_original.copy()
            df_rs_input = df_rs_input.loc[:, ~df_rs_input.columns.str.startswith('Unnamed')]
            
            # Convert to string for categorical analysis
            for col in df_rs_input.columns:
                if pd.api.types.is_numeric_dtype(df_rs_input[col]) and df_rs_input[col].nunique() > 15:
                    st.warning(f"‚ö†Ô∏è C·ªôt '{col}' c√≥ nhi·ªÅu gi√° tr·ªã - n√™n r·ªùi r·∫°c h√≥a")
                df_rs_input[col] = df_rs_input[col].astype(str)
            
            st.markdown("#### ‚öôÔ∏è Ch·ªçn thu·ªôc t√≠nh")
            col_a, col_b = st.columns(2)
            with col_a:
                decision_attr = st.selectbox(
                    "üéØ Thu·ªôc t√≠nh quy·∫øt ƒë·ªãnh:",
                    df_rs_input.columns.tolist(),
                    index=len(df_rs_input.columns)-1
                )
            
            available_attrs = [col for col in df_rs_input.columns if col != decision_attr]
            with col_b:
                condition_attrs = st.multiselect(
                    "üìä Thu·ªôc t√≠nh ƒëi·ªÅu ki·ªán:",
                    available_attrs,
                    default=available_attrs[:2] if len(available_attrs) >= 2 else available_attrs
                )
            
            if decision_attr and condition_attrs:
                target_values = df_rs_input[decision_attr].unique().tolist()
                target_class = st.selectbox("üéØ L·ªõp m·ª•c ti√™u:", target_values)
                
                if st.button("üöÄ Ph√¢n t√≠ch Rough Set", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ ƒêang t√≠nh to√°n..."):
                        try:
                            lower_approx = func.rs_lower_approximation(df_rs_input, target_class, condition_attrs, decision_attr)
                            upper_approx = func.rs_upper_approximation(df_rs_input, target_class, condition_attrs, decision_attr)
                            accuracy = func.rs_accuracy(df_rs_input, target_class, condition_attrs, decision_attr)
                            dependency = func.rs_dependency(df_rs_input, condition_attrs, decision_attr)
                            reducts = func.rs_find_all_reducts(df_rs_input, available_attrs, decision_attr)
                            
                            st.markdown("### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                            
                            # Metrics
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("üéØ Lower Approx", len(lower_approx))
                            with col2:
                                st.metric("üîç Upper Approx", len(upper_approx))
                            with col3:
                                st.metric("üìä Accuracy", f"{accuracy:.3f}")
                            with col4:
                                st.metric("üîó Dependency", f"{dependency:.3f}")
                            
                            # Detailed results
                            col1, col2 = st.columns(2)
                            with col1:
                                st.markdown("#### üìã Chi ti·∫øt k·∫øt qu·∫£")
                                st.info(f"üéØ **L·ªõp m·ª•c ti√™u:** {target_class}")
                                st.info(f"üìä **Thu·ªôc t√≠nh ƒëi·ªÅu ki·ªán:** {', '.join(condition_attrs)}")
                                st.success(f"‚úÖ **Lower Approximation:** {len(lower_approx)} objects")
                                st.warning(f"‚ö†Ô∏è **Upper Approximation:** {len(upper_approx)} objects")
                            
                            with col2:
                                st.markdown("#### üîß Attribute Reducts")
                                if reducts:
                                    for i, reduct in enumerate(reducts, 1):
                                        st.success(f"**Reduct {i}:** {', '.join(reduct)}")
                                else:
                                    st.info("Kh√¥ng t√¨m th·∫•y reduct n√†o")
                            
                            # Detailed calculation explanation
                            with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                detailed_explanation = func.get_rough_set_detailed_explanation(
                                    df_rs_input, target_class, condition_attrs, decision_attr
                                )
                                st.markdown(detailed_explanation)
                                    
                        except Exception as e:
                            st.error(f"‚ùå L·ªói: {e}")
    
    # ==============================================================================
    # DECISION TREE TAB
    # ==============================================================================
    with tab3:
        st.markdown("### üå≥ Decision Tree - C√¢y quy·∫øt ƒë·ªãnh ID3")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt thu·∫≠t to√°n Decision Tree ID3", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>ID3 (Iterative Dichotomiser 3)</strong> ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Quinlan ƒë·ªÉ x√¢y d·ª±ng 
                c√¢y quy·∫øt ƒë·ªãnh t·ª´ d·ªØ li·ªáu hu·∫•n luy·ªán, t·∫°o ra c√°c lu·∫≠t ph√¢n lo·∫°i d·ªÖ hi·ªÉu.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ S</strong> = Training set (t·∫≠p hu·∫•n luy·ªán): D·ªØ li·ªáu ƒë·ªÉ x√¢y d·ª±ng c√¢y</p>
                <p><strong>‚Ä¢ A</strong> = Attribute (thu·ªôc t√≠nh): C√°c ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o</p>
                <p><strong>‚Ä¢ v‚ÇÅ, v‚ÇÇ, v‚ÇÉ...</strong> = Values (gi√° tr·ªã): C√°c gi√° tr·ªã c√≥ th·ªÉ c·ªßa thu·ªôc t√≠nh</p>
                <p><strong>‚Ä¢ E(S)</strong> = Entropy: ƒêo ƒë·ªô h·ªón lo·∫°n/kh√¥ng ƒë·ªìng nh·∫•t c·ªßa t·∫≠p d·ªØ li·ªáu</p>
                <p><strong>‚Ä¢ IG(S,A)</strong> = Information Gain: L∆∞·ª£ng th√¥ng tin thu ƒë∆∞·ª£c khi chia theo A</p>
                <p><strong>‚Ä¢ Root</strong> = Node g·ªëc, <strong>Leaf</strong> = Node l√° (k·∫øt qu·∫£ ph√¢n lo·∫°i)</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>Entropy: E(S) = -Œ£·µ¢ p·µ¢ √ó log‚ÇÇ(p·µ¢)</strong></p>
                <p>Trong ƒë√≥: p·µ¢ = t·ª∑ l·ªá samples thu·ªôc l·ªõp i trong t·∫≠p S</p>
                <hr>
                <p><strong>Information Gain: IG(S,A) = E(S) - Œ£·µ• (|S·µ•|/|S|) √ó E(S·µ•)</strong></p>
                <p>Trong ƒë√≥: S·µ• = t·∫≠p con c·ªßa S c√≥ gi√° tr·ªã thu·ªôc t√≠nh A = v</p>
                <hr>
                <p><strong>Gini Index: G(S) = 1 - Œ£·µ¢ p·µ¢¬≤</strong></p>
                <p>Ph∆∞∆°ng ph√°p thay th·∫ø cho Entropy</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán ID3:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> T√≠nh Entropy c·ªßa t·∫≠p d·ªØ li·ªáu g·ªëc S</p>
                <p><strong>B∆∞·ªõc 2:</strong> V·ªõi m·ªói thu·ªôc t√≠nh A, t√≠nh Information Gain(S,A)</p>
                <p><strong>B∆∞·ªõc 3:</strong> Ch·ªçn thu·ªôc t√≠nh c√≥ IG cao nh·∫•t l√†m root node</p>
                <p><strong>B∆∞·ªõc 4:</strong> Chia d·ªØ li·ªáu theo c√°c gi√° tr·ªã c·ªßa thu·ªôc t√≠nh ƒë√£ ch·ªçn</p>
                <p><strong>B∆∞·ªõc 5:</strong> ƒê·ªá quy cho m·ªói nh√°nh v·ªõi t·∫≠p con t∆∞∆°ng ·ª©ng</p>
                <p><strong>B∆∞·ªõc 6:</strong> D·ª´ng khi t·∫•t c·∫£ samples trong nh√°nh c√πng l·ªõp</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ Ph√¢n lo·∫°i d·ª±a tr√™n rules</p>
                <p>‚Ä¢ D·ªÖ hi·ªÉu v√† gi·∫£i th√≠ch</p>
                <p>‚Ä¢ S·ª≠ d·ª•ng Information Gain</p>
                <p>‚Ä¢ T·∫°o lu·∫≠t IF-THEN</p>
                <p>‚Ä¢ X·ª≠ l√Ω d·ªØ li·ªáu categorical t·ªët</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_dt_input = df_original.copy()
            df_dt_input = df_dt_input.loc[:, ~df_dt_input.columns.str.startswith('Unnamed')]
            
            st.markdown("#### ‚öôÔ∏è C·∫•u h√¨nh thu·ªôc t√≠nh")
            col_a, col_b = st.columns(2)
            with col_a:
                target_attr = st.selectbox(
                    "üéØ Thu·ªôc t√≠nh m·ª•c ti√™u:",
                    df_dt_input.columns.tolist(),
                    index=len(df_dt_input.columns)-1
                )
            
            available_features = [col for col in df_dt_input.columns if col != target_attr]
            with col_b:
                method = st.radio("üìä Ph∆∞∆°ng ph√°p:", ["Information Gain", "Gini Index"], horizontal=True)
                method_param = 'Gain' if 'Information' in method else 'Gini'
            
            selected_features = st.multiselect(
                "üìã Ch·ªçn thu·ªôc t√≠nh ƒë·∫ßu v√†o:",
                available_features,
                default=available_features
            )
            
            if target_attr and selected_features:
                if st.button("üöÄ X√¢y d·ª±ng Decision Tree", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ ƒêang x√¢y d·ª±ng c√¢y..."):
                        try:
                            # Prepare data
                            df_subset = df_dt_input[selected_features + [target_attr]].copy()
                            for col in df_subset.columns:
                                df_subset[col] = df_subset[col].astype(str)
                            # Remove rows with NaN values in any column
                            df_subset = df_subset.dropna()
                            # Remove rows with 'nan' string values (from str conversion)
                            df_subset = df_subset[~(df_subset == 'nan').any(axis=1)]
                            
                            if df_subset.empty:
                                st.error("‚ùå D·ªØ li·ªáu tr·ªëng sau khi x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o.")
                            else:
                                st.markdown("### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                                
                                # Feature importance
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.markdown("#### üìà ƒêi·ªÉm s·ªë thu·ªôc t√≠nh")
                                    for attr in selected_features:
                                        if method_param == 'Gain':
                                            score = func.dt_info_gain(df_subset, attr, target_attr)
                                        else:
                                            score = func.dt_gini_gain(df_subset, attr, target_attr)
                                        st.metric(f"{attr}", f"{score:.4f}")
                                
                                # Build tree
                                decision_tree = func.dt_build_tree(df_subset, selected_features, target_attr, method_param)
                                
                                with col2:
                                    st.markdown("#### üå≥ Visualization")
                                    try:
                                        graphviz_obj = func.dt_draw_tree_graphviz(decision_tree, target_attr)
                                        st.graphviz_chart(graphviz_obj)
                                    except Exception as e_graph:
                                        st.error(f"L·ªói v·∫Ω c√¢y: {e_graph}")
                                
                                # Extract rules
                                st.markdown("#### üìú C√°c lu·∫≠t r√∫t ra")
                                rules = func.dt_extract_rules(decision_tree, target_attr)
                                if rules:
                                    for i, rule in enumerate(rules, 1):
                                        st.success(f"**Lu·∫≠t {i}:** {rule}")
                                else:
                                    st.info("Kh√¥ng c√≥ lu·∫≠t n√†o ƒë∆∞·ª£c r√∫t ra")
                                
                                # Detailed calculation explanation
                                with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                    detailed_explanation = func.get_decision_tree_detailed_explanation(
                                        df_subset, selected_features, target_attr, method_param
                                    )
                                    st.markdown(detailed_explanation)
                                
                        except Exception as e:
                            import traceback
                            st.error(f"‚ùå L·ªói Decision Tree: {e}")
                            st.error(f"Chi ti·∫øt l·ªói: {traceback.format_exc()}")
    
    # ==============================================================================
    # NAIVE BAYES TAB
    # ==============================================================================
    with tab4:
        st.markdown("### üéØ Naive Bayes - Ph√¢n lo·∫°i x√°c su·∫•t")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt thu·∫≠t to√°n Naive Bayes", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>Naive Bayes</strong> l√† thu·∫≠t to√°n ph√¢n lo·∫°i d·ª±a tr√™n <strong>ƒê·ªãnh l√Ω Bayes</strong> 
                v·ªõi gi·∫£ ƒë·ªãnh "naive" r·∫±ng c√°c features ƒë·ªôc l·∫≠p v·ªõi nhau.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ X = (x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)</strong> = Feature vector: Vector ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o</p>
                <p><strong>‚Ä¢ y</strong> = Class label: Nh√£n l·ªõp c·∫ßn d·ª± ƒëo√°n</p>
                <p><strong>‚Ä¢ P(y|X)</strong> = Posterior probability: X√°c su·∫•t y x·∫£y ra khi bi·∫øt X</p>
                <p><strong>‚Ä¢ P(X|y)</strong> = Likelihood: X√°c su·∫•t X x·∫£y ra khi bi·∫øt y</p>
                <p><strong>‚Ä¢ P(y)</strong> = Prior probability: X√°c su·∫•t ti√™n nghi·ªám c·ªßa l·ªõp y</p>
                <p><strong>‚Ä¢ P(X)</strong> = Evidence: X√°c su·∫•t c·ªßa X (h·∫±ng s·ªë normalizing)</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>Bayes Theorem: P(y|X) = P(X|y) √ó P(y) / P(X)</strong></p>
                <p>X√°c su·∫•t h·∫≠u nghi·ªám = Likelihood √ó Prior / Evidence</p>
                <hr>
                <p><strong>Naive assumption: P(X|y) = ‚àè·µ¢ P(x·µ¢|y)</strong></p>
                <p>Gi·∫£ ƒë·ªãnh features ƒë·ªôc l·∫≠p ƒëi·ªÅu ki·ªán</p>
                <hr>
                <p><strong>Classification: ≈∑ = argmax_y P(y) √ó ‚àè·µ¢ P(x·µ¢|y)</strong></p>
                <p>Ch·ªçn l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> T√≠nh Prior P(y) cho m·ªói l·ªõp t·ª´ t·∫≠p hu·∫•n luy·ªán</p>
                <p><strong>B∆∞·ªõc 2:</strong> T√≠nh Likelihood P(x·µ¢|y) cho m·ªói feature v·ªõi m·ªói l·ªõp</p>
                <p><strong>B∆∞·ªõc 3:</strong> V·ªõi sample m·ªõi X, t√≠nh P(y|X) cho m·ªói l·ªõp y</p>
                <p><strong>B∆∞·ªõc 4:</strong> Ch·ªçn l·ªõp c√≥ P(y|X) cao nh·∫•t l√†m k·∫øt qu·∫£</p>
                <p><strong>Smoothing:</strong> √Åp d·ª•ng Laplace smoothing tr√°nh P=0</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="info-box">
                <h4>üîÑ C√°c bi·∫øn th·ªÉ Naive Bayes:</h4>
                <p><strong>‚Ä¢ Gaussian NB:</strong> Features li√™n t·ª•c, tu√¢n theo ph√¢n ph·ªëi chu·∫©n</p>
                <p><strong>‚Ä¢ Multinomial NB:</strong> Features r·ªùi r·∫°c, count data (text classification)</p>
                <p><strong>‚Ä¢ Bernoulli NB:</strong> Features binary (0/1)</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ Ph√¢n lo·∫°i d·ª±a tr√™n x√°c su·∫•t</p>
                <p>‚Ä¢ Nhanh v√† hi·ªáu qu·∫£</p>
                <p>‚Ä¢ Gi·∫£ ƒë·ªãnh ƒë·ªôc l·∫≠p features</p>
                <p>‚Ä¢ Ho·∫°t ƒë·ªông t·ªët v·ªõi d·ªØ li·ªáu √≠t</p>
                <p>‚Ä¢ ·ª®ng d·ª•ng: Text classification, Spam filter</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_nb_input = df_original.copy()
            df_nb_input = df_nb_input.loc[:, ~df_nb_input.columns.str.startswith('Unnamed')]
            
            st.markdown("#### ‚öôÔ∏è C·∫•u h√¨nh m√¥ h√¨nh")
            col_a, col_b = st.columns(2)
            with col_a:
                target_col = st.selectbox(
                    "üéØ C·ªôt m·ª•c ti√™u:",
                    df_nb_input.columns.tolist(),
                    index=len(df_nb_input.columns)-1
                )
            
            with col_b:
                nb_type = st.radio(
                    "üìä Lo·∫°i Naive Bayes:",
                    ["GaussianNB", "MultinomialNB"],
                    horizontal=True
                )
            
            # Additional parameters
            alpha = 1.0
            if nb_type == "MultinomialNB":
                alpha = st.slider("üéöÔ∏è Alpha (Smoothing):", 0.01, 3.0, 1.0, 0.1)
            
            if target_col:
                if st.button("üöÄ Hu·∫•n luy·ªán Naive Bayes", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ ƒêang hu·∫•n luy·ªán..."):
                        try:
                            # Preprocess data
                            X_processed, y_processed, le_y, feature_encoders = func.general_preprocess_data_nbkm(
                                df_nb_input, target_col, st_instance=st
                            )
                            
                            if X_processed is not None and y_processed is not None:
                                # Handle negative values for MultinomialNB
                                X_final = X_processed.copy()
                                
                                if nb_type == "MultinomialNB" and (X_final < 0).any().any():
                                    st.warning("‚ö†Ô∏è MultinomialNB y√™u c·∫ßu gi√° tr·ªã kh√¥ng √¢m. √Åp d·ª•ng MinMaxScaler...")
                                    scaler = MinMaxScaler()
                                    X_final = pd.DataFrame(
                                        scaler.fit_transform(X_final), 
                                        columns=X_final.columns
                                    )
                                
                                method_internal = "gaussian" if nb_type == "GaussianNB" else "multinomial"
                                model, accuracy = func.train_naive_bayes_model(
                                    X_final, y_processed, method_internal, alpha, st_instance=st
                                )
                                
                                if model:
                                    st.markdown("### üìä K·∫øt qu·∫£ hu·∫•n luy·ªán")
                                    
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("üéØ Lo·∫°i m√¥ h√¨nh", nb_type)
                                    with col2:
                                        st.metric("üìä Accuracy", f"{accuracy:.4f}")
                                    with col3:
                                        st.metric("üî¢ Alpha", f"{alpha:.2f}" if nb_type == "MultinomialNB" else "N/A")
                                    
                                    st.success("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán th√†nh c√¥ng!")
                                    
                                    # Show class distribution
                                    if le_y:
                                        st.markdown("#### üìà Ph√¢n b·ªë l·ªõp")
                                        class_dist = pd.Series(y_processed).value_counts()
                                        class_names = le_y.classes_
                                        
                                        chart_data = pd.DataFrame({
                                            'Class': [class_names[i] for i in class_dist.index],
                                            'Count': class_dist.values
                                        })
                                        st.bar_chart(chart_data.set_index('Class'))
                                    
                                    # Detailed calculation explanation
                                    with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                        detailed_explanation = func.get_naive_bayes_detailed_explanation(
                                            X_final, y_processed, method_internal
                                        )
                                        st.markdown(detailed_explanation)
                                    
                        except Exception as e:
                            st.error(f"‚ùå L·ªói: {e}")
    
    # ==============================================================================
    # K-MEANS TAB
    # ==============================================================================
    with tab5:
        st.markdown("### üë• K-Means Clustering - Ph√¢n c·ª•m")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt thu·∫≠t to√°n K-Means", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>K-Means</strong> l√† thu·∫≠t to√°n ph√¢n c·ª•m unsupervised learning, chia d·ªØ li·ªáu th√†nh 
                <strong>K c·ª•m</strong> sao cho c√°c ƒëi·ªÉm trong c√πng c·ª•m gi·ªëng nhau nh·∫•t.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ K</strong> = S·ªë c·ª•m: Tham s·ªë ƒë·∫ßu v√†o, s·ªë c·ª•m mong mu·ªën</p>
                <p><strong>‚Ä¢ X = {x‚ÇÅ, x‚ÇÇ, ..., x‚Çô}</strong> = Dataset: T·∫≠p d·ªØ li·ªáu ƒë·∫ßu v√†o</p>
                <p><strong>‚Ä¢ Œº‚Çñ</strong> = Centroid: T√¢m c·ªßa c·ª•m k (tr·ªçng t√¢m)</p>
                <p><strong>‚Ä¢ C‚Çñ</strong> = Cluster k: T·∫≠p c√°c ƒëi·ªÉm thu·ªôc c·ª•m k</p>
                <p><strong>‚Ä¢ d(x·µ¢, Œº‚Çñ)</strong> = Distance: Kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm x·µ¢ ƒë·∫øn centroid Œº‚Çñ</p>
                <p><strong>‚Ä¢ J</strong> = Cost function: H√†m m·ª•c ti√™u c·∫ßn t·ªëi thi·ªÉu h√≥a</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>Euclidean Distance: d(x·µ¢, Œº‚Çñ) = ‚àöŒ£‚±º(x·µ¢‚±º - Œº‚Çñ‚±º)¬≤</strong></p>
                <p>Kho·∫£ng c√°ch Euclidean trong kh√¥ng gian nhi·ªÅu chi·ªÅu</p>
                <hr>
                <p><strong>Centroid Update: Œº‚Çñ = (1/|C‚Çñ|) √ó Œ£_{x·µ¢‚ààC‚Çñ} x·µ¢</strong></p>
                <p>C·∫≠p nh·∫≠t centroid = trung b√¨nh c·ªßa c√°c ƒëi·ªÉm trong c·ª•m</p>
                <hr>
                <p><strong>Objective Function: J = Œ£‚Çñ Œ£_{x·µ¢‚ààC‚Çñ} ||x·µ¢ - Œº‚Çñ||¬≤</strong></p>
                <p>T·ªëi thi·ªÉu h√≥a t·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch trong c·ª•m</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán K-Means:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> Kh·ªüi t·∫°o K centroids ng·∫´u nhi√™n Œº‚ÇÅ, Œº‚ÇÇ, ..., Œº‚Çñ</p>
                <p><strong>B∆∞·ªõc 2:</strong> G√°n m·ªói ƒëi·ªÉm x·µ¢ v√†o c·ª•m g·∫ßn nh·∫•t (theo kho·∫£ng c√°ch)</p>
                <p><strong>B∆∞·ªõc 3:</strong> C·∫≠p nh·∫≠t centroids = trung b√¨nh c√°c ƒëi·ªÉm trong c·ª•m</p>
                <p><strong>B∆∞·ªõc 4:</strong> L·∫∑p b∆∞·ªõc 2-3 cho ƒë·∫øn khi centroids kh√¥ng ƒë·ªïi</p>
                <p><strong>ƒêi·ªÅu ki·ªán d·ª´ng:</strong> Centroids h·ªôi t·ª• ho·∫∑c ƒë·∫°t s·ªë iterations t·ªëi ƒëa</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="warning-box">
                <h4>‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:</h4>
                <p><strong>‚Ä¢ Ch·ªçn K:</strong> C·∫ßn bi·∫øt tr∆∞·ªõc s·ªë c·ª•m ho·∫∑c d√πng Elbow method</p>
                <p><strong>‚Ä¢ Kh·ªüi t·∫°o:</strong> K·∫øt qu·∫£ ph·ª• thu·ªôc v√†o centroid ban ƒë·∫ßu</p>
                <p><strong>‚Ä¢ Scaling:</strong> N√™n chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc khi clustering</p>
                <p><strong>‚Ä¢ Gi·∫£ ƒë·ªãnh:</strong> C·ª•m c√≥ d·∫°ng h√¨nh c·∫ßu, k√≠ch th∆∞·ªõc t∆∞∆°ng ƒë∆∞∆°ng</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ Ph√¢n chia d·ªØ li·ªáu th√†nh K c·ª•m</p>
                <p>‚Ä¢ Unsupervised learning</p>
                <p>‚Ä¢ D·ª±a tr√™n kho·∫£ng c√°ch Euclidean</p>
                <p>‚Ä¢ ·ª®ng d·ª•ng: Segmentation, Data exploration</p>
                <p>‚Ä¢ T·ªëi ∆∞u h√≥a centroids</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_km_input = df_original.copy()
            df_km_input = df_km_input.loc[:, ~df_km_input.columns.str.startswith('Unnamed')]
            
            st.markdown("#### ‚öôÔ∏è C·∫•u h√¨nh clustering")
            col_a, col_b = st.columns(2)
            with col_a:
                k_clusters = st.slider("üéØ S·ªë c·ª•m (K):", 2, 10, 3, 1)
            with col_b:
                st.metric("üìä S·ªë thu·ªôc t√≠nh", df_km_input.select_dtypes(include=[np.number]).shape[1])
            
            if st.button("üöÄ Ch·∫°y K-Means", type="primary", use_container_width=True):
                with st.spinner("‚è≥ ƒêang ph√¢n c·ª•m..."):
                    try:
                        # Preprocess data
                        X_processed, _, _, _ = func.general_preprocess_data_nbkm(
                            df_km_input, None, st_instance=st
                        )
                        
                        if X_processed is not None:
                            labels, centers, df_clustered, X_scaled = func.run_kmeans_clustering_analysis(
                                X_processed, k_clusters
                            )
                            
                            if labels is not None:
                                st.markdown("### üìä K·∫øt qu·∫£ ph√¢n c·ª•m")
                                
                                # Metrics
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("üéØ S·ªë c·ª•m", k_clusters)
                                with col2:
                                    st.metric("üìä S·ªë ƒëi·ªÉm", len(labels))
                                with col3:
                                    unique_labels, counts = np.unique(labels, return_counts=True)
                                    st.metric("üìà C·ª•m l·ªõn nh·∫•t", counts.max())
                                
                                # Show clustered data
                                col1, col2 = st.columns([1, 1])
                                with col1:
                                    st.markdown("#### üìã D·ªØ li·ªáu ƒë√£ ph√¢n c·ª•m")
                                    st.dataframe(df_clustered.head(10), use_container_width=True)
                                
                                with col2:
                                    if X_processed.shape[1] >= 2:
                                        st.markdown("#### üìà Visualization 2D")
                                        fig, ax = plt.subplots(figsize=(8, 6))
                                        scatter = ax.scatter(X_scaled[:, 0], X_scaled[:, 1], 
                                                           c=labels, cmap='viridis', alpha=0.7, edgecolors='k')
                                        ax.scatter(centers[:, 0], centers[:, 1], 
                                                 marker='X', s=200, color='red', label='Centroids')
                                        ax.set_xlabel(f"{X_processed.columns[0]} (normalized)")
                                        ax.set_ylabel(f"{X_processed.columns[1]} (normalized)")
                                        ax.set_title(f"K-Means Clustering (K={k_clusters})")
                                        ax.legend()
                                        plt.colorbar(scatter)
                                        st.pyplot(fig)
                                    else:
                                        st.info("C·∫ßn √≠t nh·∫•t 2 thu·ªôc t√≠nh ƒë·ªÉ visualization 2D")
                                
                                # Cluster analysis
                                st.markdown("#### üìä Ph√¢n t√≠ch t·ª´ng c·ª•m")
                                for i in range(k_clusters):
                                    cluster_data = df_clustered[df_clustered['Cluster'] == i]
                                    with st.expander(f"C·ª•m {i} ({len(cluster_data)} ƒëi·ªÉm)"):
                                        st.dataframe(cluster_data.head())
                                
                                # Detailed calculation explanation
                                with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                    detailed_explanation = func.get_kmeans_detailed_explanation(
                                        X_processed, k_clusters, random_state=42
                                    )
                                    st.markdown(detailed_explanation)
                                        
                    except Exception as e:
                        st.error(f"‚ùå L·ªói: {e}")
    
    # ==============================================================================
    # SOM TAB
    # ==============================================================================
    with tab6:
        st.markdown("### üó∫Ô∏è Kohonen SOM - B·∫£n ƒë·ªì t·ª± t·ªï ch·ª©c")
        
        # Detailed algorithm explanation
        with st.expander("üìö Gi·∫£i th√≠ch chi ti·∫øt thu·∫≠t to√°n Kohonen SOM", expanded=False):
            st.markdown("""
            <div class="explanation-box">
                <h4>üéØ M·ª•c ƒë√≠ch thu·∫≠t to√°n</h4>
                <p><strong>Self-Organizing Map (SOM)</strong> ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Kohonen, l√† m·∫°ng neural 
                kh√¥ng gi√°m s√°t ƒë·ªÉ <strong>√°nh x·∫° d·ªØ li·ªáu nhi·ªÅu chi·ªÅu xu·ªëng 2D</strong> v√† ph√°t hi·ªán patterns.</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="variable-explanation">
                <h4>üìñ Gi·∫£i th√≠ch k√Ω hi·ªáu:</h4>
                <p><strong>‚Ä¢ X = (x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)</strong> = Input vector: Vector ƒë·∫ßu v√†o n chi·ªÅu</p>
                <p><strong>‚Ä¢ W_ij = (w‚ÇÅ, w‚ÇÇ, ..., w‚Çô)</strong> = Weight vector: Vector tr·ªçng s·ªë c·ªßa neuron (i,j)</p>
                <p><strong>‚Ä¢ BMU</strong> = Best Matching Unit: Neuron c√≥ tr·ªçng s·ªë g·∫ßn nh·∫•t v·ªõi input</p>
                <p><strong>‚Ä¢ œÉ(t)</strong> = Neighborhood radius: B√°n k√≠nh l√°ng gi·ªÅng t·∫°i th·ªùi ƒëi·ªÉm t</p>
                <p><strong>‚Ä¢ Œ±(t)</strong> = Learning rate: T·ªëc ƒë·ªô h·ªçc t·∫°i th·ªùi ƒëi·ªÉm t</p>
                <p><strong>‚Ä¢ h_ij(t)</strong> = Neighborhood function: H√†m l√°ng gi·ªÅng</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="formula-box">
                <h4>üìê C√¥ng th·ª©c t√≠nh to√°n:</h4>
                <p><strong>BMU: c = argmin_i ||X - W_i||</strong></p>
                <p>T√¨m neuron c√≥ tr·ªçng s·ªë g·∫ßn nh·∫•t v·ªõi input X</p>
                <hr>
                <p><strong>Distance: d_ij = ||r_i - r_j||</strong></p>
                <p>Kho·∫£ng c√°ch v·ªã tr√≠ gi·ªØa neuron i v√† j tr√™n l∆∞·ªõi</p>
                <hr>
                <p><strong>Neighborhood: h_ij(t) = exp(-d_ij¬≤ / 2œÉ(t)¬≤)</strong></p>
                <p>H√†m Gaussian x√°c ƒë·ªãnh ·∫£nh h∆∞·ªüng l√°ng gi·ªÅng</p>
                <hr>
                <p><strong>Weight Update: W_i(t+1) = W_i(t) + Œ±(t) √ó h_ci(t) √ó (X - W_i(t))</strong></p>
                <p>C·∫≠p nh·∫≠t tr·ªçng s·ªë theo h∆∞·ªõng input</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="step-explanation">
                <h4>üîÑ C√°c b∆∞·ªõc th·ª±c hi·ªán SOM:</h4>
                <p><strong>B∆∞·ªõc 1:</strong> Kh·ªüi t·∫°o l∆∞·ªõi neurons v·ªõi tr·ªçng s·ªë ng·∫´u nhi√™n</p>
                <p><strong>B∆∞·ªõc 2:</strong> Ch·ªçn ng·∫´u nhi√™n input vector X t·ª´ dataset</p>
                <p><strong>B∆∞·ªõc 3:</strong> T√¨m BMU - neuron c√≥ tr·ªçng s·ªë g·∫ßn X nh·∫•t</p>
                <p><strong>B∆∞·ªõc 4:</strong> C·∫≠p nh·∫≠t tr·ªçng s·ªë BMU v√† c√°c neuron l√°ng gi·ªÅng</p>
                <p><strong>B∆∞·ªõc 5:</strong> Gi·∫£m learning rate Œ±(t) v√† neighborhood radius œÉ(t)</p>
                <p><strong>B∆∞·ªõc 6:</strong> L·∫∑p l·∫°i cho ƒë·∫øn h·ªôi t·ª• ho·∫∑c ƒë·∫°t max iterations</p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("""
            <div class="info-box">
                <h4>üé® ·ª®ng d·ª•ng SOM:</h4>
                <p><strong>‚Ä¢ Data Visualization:</strong> Hi·ªÉn th·ªã d·ªØ li·ªáu nhi·ªÅu chi·ªÅu tr√™n 2D map</p>
                <p><strong>‚Ä¢ Clustering:</strong> Ph√°t hi·ªán c√°c nh√≥m d·ªØ li·ªáu t∆∞∆°ng t·ª±</p>
                <p><strong>‚Ä¢ Feature Detection:</strong> T√¨m patterns ·∫©n trong d·ªØ li·ªáu</p>
                <p><strong>‚Ä¢ Dimensionality Reduction:</strong> Gi·∫£m chi·ªÅu d·ªØ li·ªáu</p>
            </div>
            """, unsafe_allow_html=True)
        
        col1, col2 = st.columns([2, 1])
        with col2:
            st.markdown("""
            <div class="algorithm-card">
                <h4>üìù Th√¥ng tin thu·∫≠t to√°n</h4>
                <p>‚Ä¢ Neural network kh√¥ng gi√°m s√°t</p>
                <p>‚Ä¢ Gi·∫£m chi·ªÅu d·ªØ li·ªáu</p>
                <p>‚Ä¢ Visualization patterns</p>
                <p>‚Ä¢ Topology preserving mapping</p>
                <p>‚Ä¢ Competitive learning</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col1:
            df_som_input = df_original.copy()
            df_som_input = df_som_input.loc[:, ~df_som_input.columns.str.startswith('Unnamed')]
            
            st.markdown("#### ‚öôÔ∏è C·∫•u h√¨nh SOM")
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                som_rows = st.number_input("üìè S·ªë h√†ng l∆∞·ªõi:", 3, 10, 4, 1)
                som_cols = st.number_input("üìê S·ªë c·ªôt l∆∞·ªõi:", 3, 10, 4, 1)
            with col_b:
                sigma = st.slider("üéöÔ∏è Sigma:", 0.1, 3.0, 1.0, 0.1)
                learning_rate = st.slider("üìà Learning Rate:", 0.01, 1.0, 0.5, 0.01)
            with col_c:
                iterations = st.number_input("üîÑ Iterations:", 100, 2000, 500, 100)
                num_classes = st.number_input("üè∑Ô∏è S·ªë l·ªõp hi·ªÉn th·ªã:", 1, 5, 3, 1)
            
            if st.button("üöÄ Hu·∫•n luy·ªán SOM", type="primary", use_container_width=True):
                with st.spinner("‚è≥ ƒêang hu·∫•n luy·ªán SOM..."):
                    try:
                        # Preprocess data
                        X_processed, _, _, _ = func.general_preprocess_data_nbkm(
                            df_som_input, None, st_instance=st
                        )
                        
                        if X_processed is not None:
                            som_model, X_scaled = func.train_kohonen_som_model(
                                X_processed, som_rows, som_cols, sigma, learning_rate, iterations, st_instance=st
                            )
                            
                            if som_model and X_scaled is not None:
                                st.markdown("### üìä K·∫øt qu·∫£ SOM")
                                
                                # Metrics
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("üó∫Ô∏è K√≠ch th∆∞·ªõc l∆∞·ªõi", f"{som_rows}x{som_cols}")
                                with col2:
                                    st.metric("üìä Sigma", f"{sigma:.2f}")
                                with col3:
                                    st.metric("üìà Learning Rate", f"{learning_rate:.2f}")
                                with col4:
                                    st.metric("üîÑ Iterations", iterations)
                                
                                # Visualization
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.markdown("#### üî• Hit Map")
                                    activation_response = som_model.activation_response(X_scaled).T
                                    fig_hit, ax_hit = plt.subplots(figsize=(som_cols*0.8, som_rows*0.8))
                                    im = ax_hit.pcolor(activation_response, cmap='viridis')
                                    ax_hit.set_title('SOM Hit Map')
                                    plt.colorbar(im, ax=ax_hit)
                                    st.pyplot(fig_hit)
                                
                                with col2:
                                    st.markdown("#### üé® Component Maps")
                                    # Random class visualization
                                    random_labels = np.random.randint(0, num_classes, size=X_scaled.shape[0])
                                    
                                    n_cols = min(num_classes, 2)
                                    n_rows = math.ceil(num_classes / n_cols)
                                    fig_comp, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3))
                                    
                                    if num_classes == 1:
                                        axes = [axes]
                                    else:
                                        axes = axes.flatten()
                                    
                                    for i in range(num_classes):
                                        if i < len(axes):
                                            class_data = X_scaled[random_labels == i]
                                            if len(class_data) > 0:
                                                win_map = som_model.win_map(class_data)
                                                heatmap = np.zeros((som_rows, som_cols))
                                                for pos, neurons in win_map.items():
                                                    heatmap[pos[0], pos[1]] = len(neurons)
                                                
                                                sns.heatmap(heatmap.T, ax=axes[i], cmap="coolwarm", 
                                                          annot=True, fmt=".0f", cbar=False)
                                                axes[i].set_title(f"Class {i}")
                                            else:
                                                axes[i].set_title(f"Class {i} (Empty)")
                                                axes[i].axis('off')
                                        else:
                                            axes[i].axis('off')
                                    
                                    plt.tight_layout()
                                    st.pyplot(fig_comp)
                                
                                st.success("‚úÖ SOM ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán th√†nh c√¥ng!")
                                
                                # Detailed calculation explanation
                                with st.expander("üßÆ Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc t√≠nh to√°n", expanded=False):
                                    detailed_explanation = func.get_som_detailed_explanation(
                                        X_processed, grid_size=(som_rows, som_cols), 
                                        learning_rate=learning_rate, epochs=iterations
                                    )
                                    st.markdown(detailed_explanation)
                                
                    except Exception as e:
                        st.error(f"‚ùå L·ªói: {e}")

else:
    # Welcome screen when no data is loaded
    st.markdown("""
    <div style="text-align: center; padding: 50px;">
        <h2>üöÄ Ch√†o m·ª´ng ƒë·∫øn v·ªõi Data Mining Toolkit!</h2>
        <p style="font-size: 18px;">
            T·∫£i l√™n file CSV ho·∫∑c ch·ªçn d·ªØ li·ªáu m·∫´u t·ª´ sidebar ƒë·ªÉ b·∫Øt ƒë·∫ßu
        </p>
        <div style="margin: 30px 0;">
            <h3>üìö 6 thu·∫≠t to√°n ƒë∆∞·ª£c h·ªó tr·ª£:</h3>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # Algorithm overview cards using CSS classes
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="info-box" style="border-left-color: #007bff;">
            <h4>üõí Apriori</h4>
            <p>T√¨m lu·∫≠t k·∫øt h·ª£p trong d·ªØ li·ªáu giao d·ªãch</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="info-box" style="border-left-color: #dc3545;">
            <h4>üéØ Naive Bayes</h4>
            <p>Ph√¢n lo·∫°i d·ª±a tr√™n x√°c su·∫•t</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="info-box" style="border-left-color: #28a745;">
            <h4>‚öñÔ∏è Rough Set</h4>
            <p>X·ª≠ l√Ω d·ªØ li·ªáu kh√¥ng ch·∫Øc ch·∫Øn</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="info-box" style="border-left-color: #6f42c1;">
            <h4>üë• K-Means</h4>
            <p>Ph√¢n c·ª•m d·ªØ li·ªáu kh√¥ng gi√°m s√°t</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="info-box" style="border-left-color: #ffc107;">
            <h4>üå≥ Decision Tree</h4>
            <p>X√¢y d·ª±ng c√¢y quy·∫øt ƒë·ªãnh ID3</p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div class="info-box" style="border-left-color: #20c997;">
            <h4>üó∫Ô∏è Kohonen SOM</h4>
            <p>B·∫£n ƒë·ªì t·ª± t·ªï ch·ª©c neural network</p>
        </div>
        """, unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p>üéì <strong>Data Mining Toolkit</strong> - ƒê·ªì √°n cu·ªëi k·ª≥ Khai th√°c D·ªØ li·ªáu</p>
    <p>ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi: Tr·∫ßn Nh·∫≠t Kh√°nh & Tr·∫ßn Nh·∫≠t Huy</p>
</div>
""", unsafe_allow_html=True) 