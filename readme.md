# ğŸ“š HÆ¯á»šNG DáºªN CÃC THUáº¬T TOÃN KHAI THÃC Dá»® LIá»†U

## ğŸ“‹ Má»¥c lá»¥c

1. [Apriori - Luáº­t Káº¿t Há»£p](#1-apriori---luáº­t-káº¿t-há»£p)
2. [Rough Set - LÃ½ Thuyáº¿t Táº­p ThÃ´](#2-rough-set---lÃ½-thuyáº¿t-táº­p-thÃ´)
3. [Decision Tree ID3 - CÃ¢y Quyáº¿t Äá»‹nh](#3-decision-tree-id3---cÃ¢y-quyáº¿t-Ä‘á»‹nh)
4. [Naive Bayes - PhÃ¢n Loáº¡i XÃ¡c Suáº¥t](#4-naive-bayes---phÃ¢n-loáº¡i-xÃ¡c-suáº­t)
5. [K-Means - PhÃ¢n Cá»¥m](#5-k-means---phÃ¢n-cá»¥m)
6. [Kohonen SOM - Báº£n Äá»“ Tá»± Tá»• Chá»©c](#6-kohonen-som---báº£n-Ä‘á»“-tá»±-tá»•-chá»©c)
7. [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng App](#7-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng-app)

## ğŸš€ Giá»›i thiá»‡u dá»± Ã¡n

ÄÃ¢y lÃ  á»©ng dá»¥ng **Streamlit** triá»ƒn khai 6 thuáº­t toÃ¡n khai thÃ¡c dá»¯ liá»‡u chÃ­nh vá»›i giao diá»‡n tÆ°Æ¡ng tÃ¡c thÃ¢n thiá»‡n. Má»—i thuáº­t toÃ¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n khÃ¡c nhau trong phÃ¢n tÃ­ch dá»¯ liá»‡u.

### ğŸ“ Cáº¥u trÃºc dá»± Ã¡n:

```
ğŸ“‚ Dá»± Ã¡n Data Mining
â”œâ”€â”€ ğŸ“„ app.py              # Giao diá»‡n Streamlit chÃ­nh
â”œâ”€â”€ ğŸ“„ func.py             # Logic thuáº­t toÃ¡n
â”œâ”€â”€ ğŸ“„ sample_data.csv     # Dá»¯ liá»‡u máº«u
â”œâ”€â”€ ğŸ“„ run_demo.bat        # Script khá»Ÿi cháº¡y
â”œâ”€â”€ ğŸ“„ DEMO_CHEATSHEET.md  # Tham kháº£o demo
â””â”€â”€ ğŸ“„ readme.md           # TÃ i liá»‡u nÃ y
```

---

# 1. APRIORI - LUáº¬T Káº¾T Há»¢P

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Apriori lÃ  gÃ¬?

HÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n lÃ  chá»§ siÃªu thá»‹ vÃ  muá»‘n biáº¿t khÃ¡ch hÃ ng thÆ°á»ng mua nhá»¯ng gÃ¬ cÃ¹ng nhau!

**VÃ­ dá»¥ Ä‘á»i thÆ°á»ng:**

```
ğŸ›’ Giá» hÃ ng 1: BÃ¡nh mÃ¬ + Sá»¯a + BÆ¡
ğŸ›’ Giá» hÃ ng 2: BÃ¡nh mÃ¬ + Sá»¯a
ğŸ›’ Giá» hÃ ng 3: Sá»¯a + PhÃ´ mai
ğŸ›’ Giá» hÃ ng 4: BÃ¡nh mÃ¬ + Sá»¯a + PhÃ´ mai
```

**Apriori sáº½ tÃ¬m ra:**

- "Náº¿u ai mua **BÃ¡nh mÃ¬** thÃ¬ **80%** cÅ©ng mua **Sá»¯a**"
- "Náº¿u ai mua **Sá»¯a** vÃ  **BÃ¡nh mÃ¬** thÃ¬ **60%** cÅ©ng mua **BÆ¡**"

### Táº¡i sao quan trá»ng?

- ğŸ¯ **Bá»‘ trÃ­ hÃ ng hÃ³a**: Äáº·t sá»¯a gáº§n bÃ¡nh mÃ¬
- ğŸ“ˆ **Khuyáº¿n mÃ£i**: Giáº£m giÃ¡ combo bÃ¡nh mÃ¬ + sá»¯a
- ğŸ’¡ **Gá»£i Ã½ mua hÃ ng**: "KhÃ¡ch hÃ ng Ä‘Ã£ mua bÃ¡nh mÃ¬, cÃ³ thá»ƒ thÃ­ch sá»¯a"

### CÃ¡c khÃ¡i niá»‡m Ä‘Æ¡n giáº£n:

- **Support (Há»— trá»£)**: CÃ³ bao nhiá»u % khÃ¡ch hÃ ng mua item nÃ y?
  - VD: 70% khÃ¡ch mua bÃ¡nh mÃ¬ â†’ Support(BÃ¡nh mÃ¬) = 0.7
- **Confidence (Tin cáº­y)**: Náº¿u mua A thÃ¬ kháº£ nÄƒng mua B lÃ  bao nhiá»u?
  - VD: Trong sá»‘ ngÆ°á»i mua bÃ¡nh mÃ¬, 80% cÅ©ng mua sá»¯a â†’ Conf(BÃ¡nh mÃ¬ â†’ Sá»¯a) = 0.8

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ“Š TÃ¹y chá»n tiá»n xá»­ lÃ½ dá»¯ liá»‡u:

1. **One-hot encode cÃ¡c cá»™t Ä‘Æ°á»£c chá»n**

   - DÃ¹ng cho dá»¯ liá»‡u giao dá»‹ch (TransactionID, Product)
   - Chuyá»ƒn categorical data thÃ nh dáº¡ng binary matrix
   - **Khi nÃ o dÃ¹ng**: CÃ³ dá»¯ liá»‡u dáº¡ng giao dá»‹ch rÃµ rÃ ng

2. **Sá»­ dá»¥ng cÃ¡c cá»™t sá»‘ gá»‘c**

   - DÃ¹ng trá»±c tiáº¿p dá»¯ liá»‡u sá»‘
   - **LÆ°u Ã½**: Chá»‰ phÃ¹ há»£p khi dá»¯ liá»‡u Ä‘Ã£ á»Ÿ dáº¡ng 0/1

3. **Chuyá»ƒn Ä‘á»•i toÃ n bá»™ sang boolean**
   - Biáº¿n táº¥t cáº£ thÃ nh True/False
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u há»—n há»£p nhiá»u loáº¡i

### ğŸšï¸ Tham sá»‘ chÃ­nh:

- **Min Support (0.01-1.0)**: Tá»· lá»‡ tá»‘i thiá»ƒu xuáº¥t hiá»‡n cá»§a itemset
  - Tháº¥p (0.1-0.3): Nhiá»u pattern, cÃ³ thá»ƒ nhiá»u noise
  - Cao (0.5-0.8): Ãt pattern, chá»‰ nhá»¯ng máº«u ráº¥t phá»• biáº¿n
- **Min Confidence (0.01-1.0)**: Äá»™ tin cáº­y tá»‘i thiá»ƒu cá»§a luáº­t
  - Tháº¥p (0.3-0.5): Nhiá»u luáº­t, Ä‘á»™ tin cáº­y tháº¥p
  - Cao (0.7-0.9): Ãt luáº­t, Ä‘á»™ tin cáº­y cao

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh nghÄ©a chÃ­nh thá»©c:

Apriori lÃ  thuáº­t toÃ¡n tÃ¬m **frequent itemsets** vÃ  **association rules** tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u giao dá»‹ch.

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

**ğŸ”¸ VÃ­ dá»¥ thá»±c táº¿ tá»« file `data_apriori_to_OHE.csv`:**

```
Dá»¯ liá»‡u gá»‘c (giao dá»‹ch):
MÃ£ hÃ³a Ä‘Æ¡n | MÃ£ hÃ ng
o1        | i1, i2, i3
o2        | i2, i3, i4
o3        | i2, i3, i4
o4        | i1, i2, i3
o5        | i3, i4

Sau khi chuyá»ƒn Ä‘á»•i thÃ nh Binary Matrix:
     | i1 | i2 | i3 | i4
-----|----|----|----|----|
o1   | 1  | 1  | 1  | 0
o2   | 0  | 1  | 1  | 1
o3   | 0  | 1  | 1  | 1
o4   | 1  | 1  | 1  | 0
o5   | 0  | 0  | 1  | 1
```

**ğŸ”¸ VÃ­ dá»¥ tá»« file `data_apriori.csv` (dá»¯ liá»‡u Ä‘Ã£ á»Ÿ dáº¡ng binary):**

```
     | i1 | i2 | i3 | i4
-----|----|----|----|----|
o1   | 1  | 1  | 1  | 0
o2   | 0  | 1  | 1  | 1
o3   | 0  | 1  | 1  | 1
o4   | 1  | 1  | 1  | 0
o5   | 0  | 0  | 1  | 1
```

#### BÆ°á»›c 2: TÃ¬m Frequent 1-itemsets (Lâ‚)

```python
# Äáº¿m frequency cá»§a tá»«ng item (vá»›i min_support = 0.4)
Tá»•ng sá»‘ giao dá»‹ch: 5

support(i1) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep
support(i2) = 3/5 = 0.6 â‰¥ 0.4 â†’ Keep
support(i3) = 5/5 = 1.0 â‰¥ 0.4 â†’ Keep
support(i4) = 3/5 = 0.6 â‰¥ 0.4 â†’ Keep

Lâ‚ = {i1, i2, i3, i4}  # Táº¥t cáº£ Ä‘á»u frequent
```

#### BÆ°á»›c 3: Sinh Candidate 2-itemsets (Câ‚‚)

```python
# Káº¿t há»£p cÃ¡c frequent 1-itemsets
Lâ‚ = {i1, i2, i3, i4}
Câ‚‚ = {(i1,i2), (i1,i3), (i1,i4), (i2,i3), (i2,i4), (i3,i4)}
```

#### BÆ°á»›c 4: TÃ­nh Support vÃ  lá»c â†’ Lâ‚‚

```python
# Äáº¿m support cá»§a tá»«ng 2-itemset
support(i1,i2) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep (o1,o4)
support(i1,i3) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep (o1,o4)
support(i1,i4) = 0/5 = 0.0 < 0.4 â†’ Remove
support(i2,i3) = 3/5 = 0.6 â‰¥ 0.4 â†’ Keep (o1,o2,o3,o4)
support(i2,i4) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep (o2,o3)
support(i3,i4) = 3/5 = 0.6 â‰¥ 0.4 â†’ Keep (o2,o3,o5)

Lâ‚‚ = {(i1,i2), (i1,i3), (i2,i3), (i2,i4), (i3,i4)}
```

#### BÆ°á»›c 5: Sinh Candidate 3-itemsets (Câ‚ƒ)

```python
# Káº¿t há»£p cÃ¡c 2-itemsets cÃ³ chung 1 item
Câ‚ƒ = {(i1,i2,i3), (i2,i3,i4)}

support(i1,i2,i3) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep (o1,o4)
support(i2,i3,i4) = 2/5 = 0.4 â‰¥ 0.4 â†’ Keep (o2,o3)

Lâ‚ƒ = {(i1,i2,i3), (i2,i3,i4)}
```

#### BÆ°á»›c 6: Thá»­ sinh 4-itemsets

```python
Câ‚„ = {(i1,i2,i3,i4)}
support(i1,i2,i3,i4) = 0/5 = 0.0 < 0.4 â†’ Remove

Lâ‚„ = {} â†’ Dá»«ng thuáº­t toÃ¡n
```

#### BÆ°á»›c 7: Sinh Association Rules (vá»›i min_confidence = 0.6)

```python
# Tá»« frequent itemsets, sinh cÃ¡c luáº­t:

Tá»« (i1,i2,i3):
- i1 â†’ (i2,i3): conf = 0.4/0.4 = 1.0 â‰¥ 0.6 âœ“
- i2 â†’ (i1,i3): conf = 0.4/0.6 = 0.67 â‰¥ 0.6 âœ“
- i3 â†’ (i1,i2): conf = 0.4/1.0 = 0.4 < 0.6 âœ—
- (i1,i2) â†’ i3: conf = 0.4/0.4 = 1.0 â‰¥ 0.6 âœ“

Tá»« (i2,i3,i4):
- i2 â†’ (i3,i4): conf = 0.4/0.6 = 0.67 â‰¥ 0.6 âœ“
- i3 â†’ (i2,i4): conf = 0.4/1.0 = 0.4 < 0.6 âœ—
- i4 â†’ (i2,i3): conf = 0.4/0.6 = 0.67 â‰¥ 0.6 âœ“
```

### ğŸ¯ **Káº¾T QUáº¢ CUá»I CÃ™NG APRIORI:**

```
ğŸ“Š FREQUENT ITEMSETS:
- 1-itemsets: {i1}, {i2}, {i3}, {i4}
- 2-itemsets: {i1,i2}, {i1,i3}, {i2,i3}, {i2,i4}, {i3,i4}
- 3-itemsets: {i1,i2,i3}, {i2,i3,i4}

ğŸ¯ ASSOCIATION RULES (confidence â‰¥ 0.6):
1. i1 â†’ {i2,i3} (conf: 1.0, lift: 1.67)
2. i2 â†’ {i1,i3} (conf: 0.67, lift: 1.67)
3. {i1,i2} â†’ i3 (conf: 1.0, lift: 1.0)
4. i2 â†’ {i3,i4} (conf: 0.67, lift: 1.11)
5. i4 â†’ {i2,i3} (conf: 0.67, lift: 1.11)

ğŸ’¡ INSIGHTS:
- Item i3 xuáº¥t hiá»‡n trong táº¥t cáº£ giao dá»‹ch (support = 1.0)
- Náº¿u mua i1 thÃ¬ cháº¯c cháº¯n sáº½ mua cáº£ i2 vÃ  i3
- Items i2, i3, i4 thÆ°á»ng xuáº¥t hiá»‡n cÃ¹ng nhau
```

### CÃ¡c bÆ°á»›c thuáº­t toÃ¡n:

1. **TÃ¬m frequent 1-itemsets** (Lâ‚)
2. **Sinh candidate 2-itemsets** (Câ‚‚) tá»« Lâ‚
3. **TÃ­nh support vÃ  lá»c** â†’ Lâ‚‚
4. **Láº·p láº¡i** cho Ä‘áº¿n khi khÃ´ng cÃ²n frequent itemsets

### CÃ´ng thá»©c toÃ¡n há»c:

**Support:**

```
Support(A) = |T(A)| / |T|
```

Trong Ä‘Ã³: |T(A)| = sá»‘ giao dá»‹ch chá»©a A, |T| = tá»•ng sá»‘ giao dá»‹ch

**Confidence:**

```
Confidence(A â†’ B) = Support(A âˆª B) / Support(A)
```

**Lift:**

```
Lift(A â†’ B) = Support(A âˆª B) / (Support(A) Ã— Support(B))
```

### Pseudocode:

```python
def apriori(transactions, min_support):
    L1 = find_frequent_1_itemsets(transactions, min_support)
    L = [L1]
    k = 2

    while L[k-2] is not empty:
        Ck = apriori_gen(L[k-2])  # Generate candidates
        for transaction in transactions:
            Ct = subset(Ck, transaction)  # Candidates in transaction
            for candidate in Ct:
                candidate.count++

        Lk = {c in Ck | c.support >= min_support}
        L.append(Lk)
        k = k + 1

    return union(L)
```

---

# 2. ROUGH SET - LÃ THUYáº¾T Táº¬P THÃ”

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Rough Set lÃ  gÃ¬?

HÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n muá»‘n phÃ¢n loáº¡i há»c sinh "Giá»i" hay "Yáº¿u" dá»±a trÃªn Ä‘iá»ƒm sá»‘, nhÆ°ng cÃ³ má»™t sá»‘ trÆ°á»ng há»£p khÃ´ng rÃµ rÃ ng!

**VÃ­ dá»¥:**

```
Há»c sinh A: ToÃ¡n=8, LÃ½=7, HÃ³a=9 â†’ Giá»i âœ“
Há»c sinh B: ToÃ¡n=5, LÃ½=4, HÃ³a=6 â†’ Yáº¿u âœ“
Há»c sinh C: ToÃ¡n=7, LÃ½=6, HÃ³a=5 â†’ ??? (KhÃ´ng cháº¯c)
```

### Rough Set giÃºp gÃ¬?

- ğŸ¯ **TÃ¬m thuá»™c tÃ­nh quan trá»ng**: MÃ´n nÃ o quyáº¿t Ä‘á»‹nh "Giá»i/Yáº¿u"?
- ğŸ” **Xá»­ lÃ½ khÃ´ng cháº¯c cháº¯n**: PhÃ¢n loáº¡i nhá»¯ng trÆ°á»ng há»£p mÆ¡ há»“
- âœ‚ï¸ **Giáº£m thuá»™c tÃ­nh**: Loáº¡i bá» thÃ´ng tin thá»«a

### CÃ¡c khÃ¡i niá»‡m Ä‘Æ¡n giáº£n:

- **Lower Approximation (Xáº¥p xá»‰ dÆ°á»›i)**: Nhá»¯ng trÆ°á»ng há»£p **CHáº®C CHáº®N** thuá»™c nhÃ³m
- **Upper Approximation (Xáº¥p xá»‰ trÃªn)**: Nhá»¯ng trÆ°á»ng há»£p **CÃ“ THá»‚** thuá»™c nhÃ³m
- **Boundary Region (VÃ¹ng biÃªn)**: Nhá»¯ng trÆ°á»ng há»£p **KHÃ”NG CHáº®C**

### Minh há»a trá»±c quan:

```
ğŸ¯ Má»¥c tiÃªu: PhÃ¢n loáº¡i "Há»c sinh giá»i"

Lower Approximation (Cháº¯c cháº¯n giá»i):
ğŸ‘¨â€ğŸ“ ToÃ¡nâ‰¥8 AND LÃ½â‰¥8 â†’ 100% Giá»i

Upper Approximation (CÃ³ thá»ƒ giá»i):
ğŸ‘¨â€ğŸ“ ToÃ¡nâ‰¥6 OR LÃ½â‰¥6 â†’ CÃ³ thá»ƒ Giá»i

Boundary Region (KhÃ´ng cháº¯c):
ğŸ‘¨â€ğŸ“ 6â‰¤ToÃ¡n<8 AND 6â‰¤LÃ½<8 â†’ Cáº§n xem thÃªm
```

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n thuá»™c tÃ­nh:

- **Thuá»™c tÃ­nh quyáº¿t Ä‘á»‹nh**: Cá»™t chá»©a káº¿t quáº£ cáº§n dá»± Ä‘oÃ¡n (VD: "PhÃ¢n loáº¡i", "Káº¿t quáº£")
- **Thuá»™c tÃ­nh Ä‘iá»u kiá»‡n**: CÃ¡c cá»™t Ä‘áº·c trÆ°ng Ä‘á»ƒ phÃ¢n tÃ­ch (VD: "Äiá»ƒm toÃ¡n", "Äiá»ƒm lÃ½")

### ğŸ† Chá»n lá»›p má»¥c tiÃªu:

- Chá»n giÃ¡ trá»‹ cá»¥ thá»ƒ muá»‘n phÃ¢n tÃ­ch (VD: "Giá»i", "Yáº¿u", "Trung bÃ¬nh")

### ğŸ’¡ LÆ°u Ã½ quan trá»ng:

- **Dá»¯ liá»‡u categorical**: App tá»± Ä‘á»™ng chuyá»ƒn sang string
- **Cáº£nh bÃ¡o rá»i ráº¡c hÃ³a**: Náº¿u cá»™t sá»‘ cÃ³ >15 giÃ¡ trá»‹ unique sáº½ Ä‘Æ°á»£c cáº£nh bÃ¡o

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh nghÄ©a toÃ¡n há»c:

Cho táº­p vÅ© trá»¥ U, quan há»‡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng R, vÃ  táº­p má»¥c tiÃªu X âŠ† U.

**Lower Approximation:**

```
R*(X) = {x âˆˆ U | [x]R âŠ† X}
```

**Upper Approximation:**

```
R*(X) = {x âˆˆ U | [x]R âˆ© X â‰  âˆ…}
```

**Boundary Region:**

```
BND_R(X) = R*(X) - R*(X)
```

### CÃ¡c thÆ°á»›c Ä‘o cháº¥t lÆ°á»£ng:

**Accuracy (Äá»™ chÃ­nh xÃ¡c):**

```
Î±_R(X) = |R*(X)| / |R*(X)|
```

**Dependency (Má»©c Ä‘á»™ phá»¥ thuá»™c):**

```
Î³_R(D) = |POS_R(D)| / |U|
```

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: XÃ¢y dá»±ng Information Table

**ğŸ”¸ VÃ­ dá»¥ thá»±c táº¿ tá»« file `data_rough_set.csv`:**

```
| ID | KÃ­ch thÆ°á»›c | MÃ u sáº¯c | HÃ¬nh dáº¡ng   | Lá»›p |
|----|------------|---------|-------------|-----|
| 1  | Vá»«a        | Xanh    | ViÃªn gáº¡ch   | A   |
| 2  | Nhá»        | Äá»      | HÃ¬nh nÃªm    | B   |
| 3  | Nhá»        | Äá»      | HÃ¬nh cáº§u    | A   |
| 4  | Lá»›n        | Äá»      | HÃ¬nh nÃªm    | B   |
| 5  | Lá»›n        | Lá»¥c     | HÃ¬nh trá»¥    | A   |
| 6  | Lá»›n        | Äá»      | HÃ¬nh trá»¥    | B   |
| 7  | Lá»›n        | Lá»¥c     | HÃ¬nh cáº§u    | A   |
```

#### BÆ°á»›c 2: Táº¡o Equivalence Classes

```python
# PhÃ¢n tÃ­ch cho Target = "A" vá»›i thuá»™c tÃ­nh Ä‘iá»u kiá»‡n [KÃ­ch thÆ°á»›c, MÃ u sáº¯c]

NhÃ³m theo [KÃ­ch thÆ°á»›c, MÃ u sáº¯c]:
E1: {1} â†’ [Vá»«a, Xanh] â†’ {A}
E2: {2,3} â†’ [Nhá», Äá»] â†’ {B, A}  # Há»—n há»£p!
E3: {4,6} â†’ [Lá»›n, Äá»] â†’ {B, B}
E4: {5,7} â†’ [Lá»›n, Lá»¥c] â†’ {A, A}
```

#### BÆ°á»›c 3: TÃ­nh Lower Approximation

```python
# TÃ¬m classes cháº¯c cháº¯n thuá»™c target "A"
Target_set = {1, 3, 5, 7}  # CÃ¡c object cÃ³ Lá»›p = "A"

Lower_Approx = {}  # Chá»‰ nhá»¯ng class hoÃ n toÃ n trong target
# E1: {1} â†’ táº¥t cáº£ thuá»™c "A" â†’ ThÃªm vÃ o Lower
# E2: {2,3} â†’ cÃ³ object 2 thuá»™c "B" â†’ KhÃ´ng thÃªm
# E3: {4,6} â†’ táº¥t cáº£ thuá»™c "B" â†’ KhÃ´ng thÃªm
# E4: {5,7} â†’ táº¥t cáº£ thuá»™c "A" â†’ ThÃªm vÃ o Lower

Lower_Approx = {1, 5, 7}
```

#### BÆ°á»›c 4: TÃ­nh Upper Approximation

```python
# TÃ¬m classes cÃ³ giao khÃ¡c rá»—ng vá»›i target "A"
Upper_Approx = {}
# E1: {1} âˆ© {1,3,5,7} = {1} â‰  âˆ… â†’ ThÃªm vÃ o Upper
# E2: {2,3} âˆ© {1,3,5,7} = {3} â‰  âˆ… â†’ ThÃªm vÃ o Upper
# E3: {4,6} âˆ© {1,3,5,7} = {} = âˆ… â†’ KhÃ´ng thÃªm
# E4: {5,7} âˆ© {1,3,5,7} = {5,7} â‰  âˆ… â†’ ThÃªm vÃ o Upper

Upper_Approx = {1, 2, 3, 5, 7}
```

#### BÆ°á»›c 5: TÃ­nh Accuracy vÃ  Dependency

```python
Accuracy = |Lower_Approx| / |Upper_Approx| = 3/5 = 0.6
Dependency = |Lower_Approx| / |Total_Objects| = 3/7 = 0.43

Boundary_Region = Upper_Approx - Lower_Approx = {2, 3}
```

#### BÆ°á»›c 6: TÃ¬m Reducts

```python
# Test tá»«ng subset cá»§a attributes vá»›i full dependency = 3/7 = 0.43

Test [KÃ­ch thÆ°á»›c]:
- Vá»«a: {1} â†’ A
- Nhá»: {2,3} â†’ B,A
- Lá»›n: {4,5,6,7} â†’ B,A,B,A
dependency = 1/7 = 0.14 â‰  0.43

Test [MÃ u sáº¯c]:
- Xanh: {1} â†’ A
- Äá»: {2,3,4,6} â†’ B,A,B,B
- Lá»¥c: {5,7} â†’ A,A
dependency = 3/7 = 0.43 = 0.43 âœ“

Test [HÃ¬nh dáº¡ng]:
- ViÃªn gáº¡ch: {1} â†’ A
- HÃ¬nh nÃªm: {2,4} â†’ B,B
- HÃ¬nh cáº§u: {3,7} â†’ A,A
- HÃ¬nh trá»¥: {5,6} â†’ A,B
dependency = 4/7 = 0.57 > 0.43

â†’ Reduct tá»‘i thiá»ƒu: {MÃ u sáº¯c}
```

### ğŸ¯ **Káº¾T QUáº¢ CUá»I CÃ™NG ROUGH SET:**

```
ğŸ“Š PHÃ‚N TÃCH CHO Lá»šP "A":

ğŸ¯ Lower Approximation: {1, 5, 7}
   - Object 1: [Vá»«a, Xanh, ViÃªn gáº¡ch] â†’ Cháº¯c cháº¯n A
   - Object 5: [Lá»›n, Lá»¥c, HÃ¬nh trá»¥] â†’ Cháº¯c cháº¯n A
   - Object 7: [Lá»›n, Lá»¥c, HÃ¬nh cáº§u] â†’ Cháº¯c cháº¯n A

ğŸ¯ Upper Approximation: {1, 2, 3, 5, 7}
   - Bao gá»“m cáº£ nhá»¯ng object cÃ³ thá»ƒ thuá»™c A

ğŸ¯ Boundary Region: {2, 3}
   - Object 2,3: [Nhá», Äá»] â†’ KhÃ´ng cháº¯c cháº¯n

ğŸ“Š Äá»˜ ÄO CHáº¤T LÆ¯á»¢NG:
- Accuracy: 0.6 (60% objects trong upper Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh)
- Dependency: 0.43 (43% objects cÃ³ thá»ƒ phÃ¢n loáº¡i cháº¯c cháº¯n)

ğŸ”§ REDUCTS:
- Reduct tá»‘i thiá»ƒu: {MÃ u sáº¯c}
- Core: {MÃ u sáº¯c} (thuá»™c tÃ­nh khÃ´ng thá»ƒ thiáº¿u)

ğŸ’¡ INSIGHTS:
- MÃ u sáº¯c lÃ  thuá»™c tÃ­nh quan trá»ng nháº¥t Ä‘á»ƒ phÃ¢n biá»‡t lá»›p A
- Objects cÃ³ mÃ u Lá»¥c luÃ´n thuá»™c lá»›p A
- Objects cÃ³ mÃ u Äá» cáº§n thÃªm thÃ´ng tin Ä‘á»ƒ phÃ¢n loáº¡i
```

### Reduct vÃ  Core:

- **Reduct**: Táº­p con tá»‘i thiá»ƒu cá»§a thuá»™c tÃ­nh váº«n giá»¯ nguyÃªn kháº£ nÄƒng phÃ¢n loáº¡i
- **Core**: Giao cá»§a táº¥t cáº£ cÃ¡c reduct (thuá»™c tÃ­nh khÃ´ng thá»ƒ thiáº¿u)

---

# 3. DECISION TREE ID3 - CÃ‚Y QUYáº¾T Äá»ŠNH

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Decision Tree lÃ  gÃ¬?

NhÆ° má»™t cÃ¢y cÃ¢u há»i Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh! Má»—i nÃºt lÃ  má»™t cÃ¢u há»i, má»—i nhÃ¡nh lÃ  má»™t Ä‘Ã¡p Ã¡n.

**VÃ­ dá»¥: CÃ³ nÃªn Ä‘i chÆ¡i khÃ´ng?**

```
ğŸŒ¤ï¸ Thá»i tiáº¿t nhÆ° tháº¿ nÃ o?
â”œâ”€â”€ â˜€ï¸ Náº¯ng
â”‚   â””â”€â”€ ğŸ˜Š Äi chÆ¡i!
â”œâ”€â”€ ğŸŒ§ï¸ MÆ°a
â”‚   â””â”€â”€ ğŸ  á» nhÃ 
â””â”€â”€ â˜ï¸ Nhiá»u mÃ¢y
    â””â”€â”€ ğŸ’° CÃ³ tiá»n khÃ´ng?
        â”œâ”€â”€ ğŸ’¸ CÃ³ â†’ ğŸ˜Š Äi chÆ¡i!
        â””â”€â”€ ğŸ’¸ KhÃ´ng â†’ ğŸ  á» nhÃ 
```

### Táº¡i sao dÃ¹ng Decision Tree?

- ğŸ“– **Dá»… hiá»ƒu**: NhÆ° sÃ¡ch hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c
- ğŸš€ **Nhanh**: Quyáº¿t Ä‘á»‹nh trong vÃ i giÃ¢y
- ğŸ¯ **ChÃ­nh xÃ¡c**: Dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿

### CÃ¡ch hoáº¡t Ä‘á»™ng:

1. **Chá»n cÃ¢u há»i tá»‘t nháº¥t** (thuá»™c tÃ­nh quan trá»ng nháº¥t)
2. **Chia dá»¯ liá»‡u** theo cÃ¢u tráº£ lá»i
3. **Láº·p láº¡i** cho Ä‘áº¿n khi cÃ³ káº¿t quáº£ rÃµ rÃ ng

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n thuá»™c tÃ­nh:

- **Thuá»™c tÃ­nh má»¥c tiÃªu**: Cá»™t cáº§n dá»± Ä‘oÃ¡n (VD: "Buy", "Class", "Result")
- **Thuá»™c tÃ­nh Ä‘áº§u vÃ o**: CÃ¡c cá»™t Ä‘áº·c trÆ°ng (VD: "Age", "Income", "Gender")

### ğŸ“Š PhÆ°Æ¡ng phÃ¡p chia nhÃ¡nh:

1. **Information Gain (Entropy)**

   - Dá»±a trÃªn lÃ½ thuyáº¿t thÃ´ng tin
   - Æ¯u tiÃªn thuá»™c tÃ­nh giáº£m entropy nhiá»u nháº¥t
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u cÃ¢n báº±ng, nhiá»u class

2. **Gini Gain**
   - Dá»±a trÃªn Ä‘á»™ báº¥t thuáº§n Gini
   - Nhanh hÆ¡n entropy
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u lá»›n, cáº§n tá»‘c Ä‘á»™

### ğŸš« LÆ°u Ã½ khi sá»­ dá»¥ng:

- App tá»± Ä‘á»™ng chuyá»ƒn táº¥t cáº£ dá»¯ liá»‡u sang string
- Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ giÃ¡ trá»‹ 'nan'
- Hiá»ƒn thá»‹ Ä‘iá»ƒm sá»‘ cá»§a tá»«ng thuá»™c tÃ­nh trÆ°á»›c khi xÃ¢y dá»±ng cÃ¢y

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Thuáº­t toÃ¡n ID3:

ID3 sá»­ dá»¥ng **Information Gain** Ä‘á»ƒ chá»n thuá»™c tÃ­nh tá»‘t nháº¥t cho má»—i nÃºt.

**Entropy:**

```
Entropy(S) = -âˆ‘(p_i Ã— logâ‚‚(p_i))
```

**Information Gain:**

```
Gain(S,A) = Entropy(S) - âˆ‘((|S_v|/|S|) Ã— Entropy(S_v))
```

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

**ğŸ”¸ VÃ­ dá»¥ thá»±c táº¿ tá»« file `data_tree.csv` (Tennis Dataset):**

```
| ID  | Outlook  | Temperature | Humidity | Wind   | Play ball |
|-----|----------|-------------|----------|--------|-----------|
| D1  | Sunny    | Hot         | High     | Weak   | No        |
| D2  | Sunny    | Hot         | High     | Strong | No        |
| D3  | Overcast | Hot         | High     | Weak   | Yes       |
| D4  | Rainy    | Mild        | High     | Weak   | Yes       |
| D5  | Rainy    | Cool        | Normal   | Weak   | Yes       |
| D6  | Rainy    | Cool        | Normal   | Strong | No        |
| D7  | Overcast | Cool        | Normal   | Strong | Yes       |
| D8  | Sunny    | Mild        | High     | Weak   | No        |
| D9  | Sunny    | Cool        | Normal   | Weak   | Yes       |
| D10 | Rainy    | Mild        | Normal   | Weak   | Yes       |
| D11 | Sunny    | Mild        | Normal   | Strong | Yes       |
| D12 | Overcast | Mild        | High     | Strong | Yes       |
| D13 | Overcast | Hot         | Normal   | Weak   | Yes       |
| D14 | Rainy    | Mild        | High     | Strong | No        |
```

#### BÆ°á»›c 2: TÃ­nh Entropy cá»§a táº­p gá»‘c

```python
Total = 14, Yes = 9, No = 5
p(Yes) = 9/14 = 0.643
p(No) = 5/14 = 0.357

Entropy(S) = -[9/14 Ã— logâ‚‚(9/14) + 5/14 Ã— logâ‚‚(5/14)]
           = -[0.643 Ã— (-0.637) + 0.357 Ã— (-1.485)]
           = 0.940
```

#### BÆ°á»›c 3: TÃ­nh Information Gain cho tá»«ng thuá»™c tÃ­nh

**Thuá»™c tÃ­nh Outlook:**

```python
# Chia theo Outlook
Sunny: {D1,D2,D8,D9,D11} â†’ 2 Yes, 3 No â†’ Entropy = 0.971
Overcast: {D3,D7,D12,D13} â†’ 4 Yes, 0 No â†’ Entropy = 0
Rainy: {D4,D5,D6,D10,D14} â†’ 3 Yes, 2 No â†’ Entropy = 0.971

Gain(Outlook) = 0.940 - [5/14Ã—0.971 + 4/14Ã—0 + 5/14Ã—0.971] = 0.246
```

**Thuá»™c tÃ­nh Temperature:**

```python
# Chia theo Temperature
Hot: {D1,D2,D3,D13} â†’ 2 Yes, 2 No â†’ Entropy = 1.0
Mild: {D4,D8,D10,D11,D12,D14} â†’ 4 Yes, 2 No â†’ Entropy = 0.918
Cool: {D5,D6,D7,D9} â†’ 3 Yes, 1 No â†’ Entropy = 0.811

Gain(Temperature) = 0.940 - [4/14Ã—1.0 + 6/14Ã—0.918 + 4/14Ã—0.811] = 0.029
```

**Thuá»™c tÃ­nh Humidity:**

```python
# Chia theo Humidity
High: {D1,D2,D3,D4,D8,D12,D14} â†’ 3 Yes, 4 No â†’ Entropy = 0.985
Normal: {D5,D6,D7,D9,D10,D11,D13} â†’ 6 Yes, 1 No â†’ Entropy = 0.592

Gain(Humidity) = 0.940 - [7/14Ã—0.985 + 7/14Ã—0.592] = 0.151
```

**Thuá»™c tÃ­nh Wind:**

```python
# Chia theo Wind
Weak: {D1,D3,D4,D5,D8,D9,D10,D13} â†’ 6 Yes, 2 No â†’ Entropy = 0.811
Strong: {D2,D6,D7,D11,D12,D14} â†’ 3 Yes, 3 No â†’ Entropy = 1.0

Gain(Wind) = 0.940 - [8/14Ã—0.811 + 6/14Ã—1.0] = 0.048
```

#### BÆ°á»›c 4: Chá»n thuá»™c tÃ­nh tá»‘t nháº¥t

```python
Gain(Outlook) = 0.246 (cao nháº¥t)
Gain(Humidity) = 0.151
Gain(Wind) = 0.048
Gain(Temperature) = 0.029

â†’ Chá»n Outlook lÃ m root node
```

#### BÆ°á»›c 5: XÃ¢y dá»±ng cÃ¢y Ä‘á»‡ quy

```
                    Outlook
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         Sunny    Overcast    Rainy
            â”‚         â”‚         â”‚
          [?]       Yes       [?]

# Sunny branch cáº§n chia tiáº¿p (2 Yes, 3 No)
# Rainy branch cáº§n chia tiáº¿p (3 Yes, 2 No)
```

**Chia nhÃ¡nh Sunny:** (D1,D2,D8,D9,D11)

```python
# Chá»‰ xÃ©t subset Sunny
Gain(Humidity) = 0.971 - [4/5Ã—0 + 1/5Ã—0] = 0.971
Gain(Wind) = 0.971 - [3/5Ã—0 + 2/5Ã—0] = 0.971
â†’ Chá»n Humidity (hoáº·c Wind, cáº£ hai Ä‘á»u perfect)

Sunny â†’ Humidity:
â”œâ”€â”€ High: No (D1,D2,D8)
â””â”€â”€ Normal: Yes (D9,D11)
```

**Chia nhÃ¡nh Rainy:** (D4,D5,D6,D10,D14)

```python
# Chá»‰ xÃ©t subset Rainy
Gain(Wind) = 0.971 - [3/5Ã—0 + 2/5Ã—0] = 0.971
â†’ Chá»n Wind

Rainy â†’ Wind:
â”œâ”€â”€ Weak: Yes (D4,D5,D10)
â””â”€â”€ Strong: No (D6,D14)
```

### ğŸ¯ **CÃ‚Y QUYáº¾T Äá»ŠNH HOÃ€N CHá»ˆNH:**

```
                    Outlook
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         Sunny    Overcast    Rainy
            â”‚         â”‚         â”‚
        Humidity     Yes      Wind
        â”Œâ”€â”€â”€â”´â”€â”€â”€â”           â”Œâ”€â”€â”€â”´â”€â”€â”€â”
      High   Normal      Weak    Strong
        â”‚       â”‚         â”‚        â”‚
       No      Yes       Yes       No
```

### ğŸ¯ **Káº¾T QUáº¢ CUá»I CÃ™NG DECISION TREE:**

```
ğŸ“Š CÃC LUáº¬T RÃšT RA:

1. IF Outlook = Overcast THEN Play = Yes
2. IF Outlook = Sunny AND Humidity = High THEN Play = No
3. IF Outlook = Sunny AND Humidity = Normal THEN Play = Yes
4. IF Outlook = Rainy AND Wind = Weak THEN Play = Yes
5. IF Outlook = Rainy AND Wind = Strong THEN Play = No

ğŸ“ˆ ÄIá»‚M Sá» CÃC THUá»˜C TÃNH:
- Outlook: 0.246 (quan trá»ng nháº¥t)
- Humidity: 0.151 (quan trá»ng thá»© 2)
- Wind: 0.048 (quan trá»ng thá»© 3)
- Temperature: 0.029 (Ã­t quan trá»ng nháº¥t)

ğŸ¯ ACCURACY: 100% (14/14 cases phÃ¢n loáº¡i Ä‘Ãºng)

ğŸ’¡ INSIGHTS:
- Outlook lÃ  yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh chÃ­nh
- Khi Overcast â†’ luÃ´n chÆ¡i tennis
- Khi Sunny â†’ phá»¥ thuá»™c Ä‘á»™ áº©m
- Khi Rainy â†’ phá»¥ thuá»™c giÃ³
- Temperature khÃ´ng áº£nh hÆ°á»Ÿng nhiá»u Ä‘áº¿n quyáº¿t Ä‘á»‹nh
```

### Pseudocode:

```python
def ID3(examples, target_attribute, attributes):
    # Base cases
    if all examples have same target value:
        return leaf node with that value

    if attributes is empty:
        return leaf node with majority target value

    # Choose best attribute
    best_attr = argmax(information_gain(examples, attr, target))

    # Create decision node
    tree = DecisionNode(best_attr)

    # Recursively build subtrees
    for value in values(best_attr):
        subset = examples where best_attr = value
        if subset is empty:
            add leaf with majority value
        else:
            remaining_attrs = attributes - {best_attr}
            subtree = ID3(subset, target_attribute, remaining_attrs)
            tree.add_branch(value, subtree)

    return tree
```

### Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm:

**Æ¯u Ä‘iá»ƒm:**

- Dá»… hiá»ƒu vÃ  giáº£i thÃ­ch
- KhÃ´ng cáº§n giáº£ Ä‘á»‹nh vá» phÃ¢n phá»‘i dá»¯ liá»‡u
- Xá»­ lÃ½ Ä‘Æ°á»£c dá»¯ liá»‡u categorical

**NhÆ°á»£c Ä‘iá»ƒm:**

- Dá»… overfitting
- ThiÃªn vá»‹ vá»›i thuá»™c tÃ­nh cÃ³ nhiá»u giÃ¡ trá»‹
- KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c dá»¯ liá»‡u thiáº¿u

---

# 4. NAIVE BAYES - PHÃ‚N LOáº I XÃC SUáº¤T

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Naive Bayes lÃ  gÃ¬?

NhÆ° má»™t bÃ¡c sÄ© cháº©n Ä‘oÃ¡n bá»‡nh dá»±a trÃªn triá»‡u chá»©ng!

**VÃ­ dá»¥: PhÃ¢n loáº¡i email spam**

```
ğŸ“§ Email cÃ³ tá»« "FREE" â†’ 80% lÃ  spam
ğŸ“§ Email cÃ³ tá»« "MONEY" â†’ 70% lÃ  spam
ğŸ“§ Email cÃ³ tá»« "URGENT" â†’ 60% lÃ  spam

ğŸ“© Email má»›i: "FREE MONEY URGENT!!!"
â†’ XÃ¡c suáº¥t spam ráº¥t cao!
```

### Táº¡i sao gá»i lÃ  "Naive" (NgÃ¢y thÆ¡)?

VÃ¬ thuáº­t toÃ¡n **giáº£ Ä‘á»‹nh** cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»™c láº­p vá»›i nhau (Ä‘iá»u nÃ y thÆ°á»ng khÃ´ng Ä‘Ãºng trong thá»±c táº¿).

**VÃ­ dá»¥ ngÃ¢y thÆ¡:**

- Giáº£ Ä‘á»‹nh: Tá»« "FREE" vÃ  "MONEY" xuáº¥t hiá»‡n Ä‘á»™c láº­p
- Thá»±c táº¿: Spam thÆ°á»ng dÃ¹ng cáº£ hai tá»« cÃ¹ng lÃºc

### CÃ¡c loáº¡i Naive Bayes:

- **Gaussian NB**: Cho dá»¯ liá»‡u sá»‘ (chiá»u cao, cÃ¢n náº·ng...)
- **Multinomial NB**: Cho dá»¯ liá»‡u Ä‘áº¿m (sá»‘ tá»« trong email...)

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n cá»™t má»¥c tiÃªu:

- Chá»n tá»« sidebar trÆ°á»›c khi cháº¡y thuáº­t toÃ¡n
- **LÆ°u Ã½**: Báº¯t buá»™c pháº£i chá»n cho Naive Bayes

### ğŸ”§ TÃ¹y chá»n loáº¡i Naive Bayes:

#### 1. **GaussianNB**

- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u sá»‘ liÃªn tá»¥c (tuá»•i, lÆ°Æ¡ng, Ä‘iá»ƒm sá»‘...)
- **Giáº£ Ä‘á»‹nh**: Features tuÃ¢n theo phÃ¢n phá»‘i Gaussian (normal)
- **Æ¯u Ä‘iá»ƒm**: KhÃ´ng cáº§n tham sá»‘, tá»± Ä‘á»™ng tÃ­nh mean vÃ  variance
- **NhÆ°á»£c Ä‘iá»ƒm**: Giáº£ Ä‘á»‹nh phÃ¢n phá»‘i cÃ³ thá»ƒ khÃ´ng Ä‘Ãºng

#### 2. **MultinomialNB**

- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u Ä‘áº¿m, frequency (text classification, word count...)
- **Tham sá»‘ Alpha**: Laplace smoothing (0.01-3.0, thÆ°á»ng 0.5-1.0)
  - Alpha tháº¥p: Ãt smoothing, cÃ³ thá»ƒ overfitting
  - Alpha cao: Nhiá»u smoothing, cÃ³ thá»ƒ underfitting
- **YÃªu cáº§u**: Táº¥t cáº£ features â‰¥ 0
- **Xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m**: TÃ­ch chá»n "Ãp dá»¥ng MinMaxScaler"

### ğŸ“Š Káº¿t quáº£ hiá»ƒn thá»‹:

- **Training Accuracy**: Äá»™ chÃ­nh xÃ¡c trÃªn táº­p huáº¥n luyá»‡n
- **Model Type**: Loáº¡i model Ä‘Ã£ train
- **Feature Info**: ThÃ´ng tin vá» features Ä‘Ã£ xá»­ lÃ½

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh lÃ½ Bayes:

```
P(C|X) = P(X|C) Ã— P(C) / P(X)
```

Trong Ä‘Ã³:

- P(C|X): XÃ¡c suáº¥t thuá»™c class C khi biáº¿t features X
- P(X|C): Likelihood - xÃ¡c suáº¥t cÃ³ features X khi thuá»™c class C
- P(C): Prior - xÃ¡c suáº¥t ban Ä‘áº§u cá»§a class C
- P(X): Evidence - xÃ¡c suáº¥t cÃ³ features X

### Giáº£ Ä‘á»‹nh Ä‘á»™c láº­p:

```
P(xâ‚,xâ‚‚,...,xâ‚™|C) = P(xâ‚|C) Ã— P(xâ‚‚|C) Ã— ... Ã— P(xâ‚™|C)
```

### CÃ´ng thá»©c tá»•ng quÃ¡t:

```
Ä‰ = argmax P(c) âˆ P(xáµ¢|c)
    câˆˆC         i=1
```

### CÃ¡c biáº¿n thá»ƒ:

### ğŸ“Š VÃ Dá»¤ CHI TIáº¾T Vá»šI Dá»® LIá»†U THá»°C Táº¾:

**ğŸ”¸ Dá»¯ liá»‡u tá»« file `data_nb.csv` (Tennis Dataset):**

```
Dá»± Ä‘oÃ¡n: CÃ³ chÆ¡i tennis hay khÃ´ng dá»±a trÃªn thá»i tiáº¿t
Target: Play ball (Yes/No)
Features: Outlook, Temperature, Humidity, Wind
```

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u vÃ  tÃ­nh Prior

```python
Total samples: 14
P(Yes) = 9/14 = 0.643
P(No) = 5/14 = 0.357
```

#### BÆ°á»›c 2: TÃ­nh Likelihood cho tá»«ng feature

**Feature: Outlook**

```python
# P(Outlook|Play=Yes)
P(Sunny|Yes) = 2/9 = 0.222      # D9,D11
P(Overcast|Yes) = 4/9 = 0.444   # D3,D7,D12,D13
P(Rainy|Yes) = 3/9 = 0.333      # D4,D5,D10

# P(Outlook|Play=No)
P(Sunny|No) = 3/5 = 0.600       # D1,D2,D8
P(Overcast|No) = 0/5 = 0.000    # KhÃ´ng cÃ³
P(Rainy|No) = 2/5 = 0.400       # D6,D14
```

**Feature: Temperature**

```python
# P(Temperature|Play=Yes)
P(Hot|Yes) = 2/9 = 0.222        # D3,D13
P(Mild|Yes) = 4/9 = 0.444       # D4,D10,D11,D12
P(Cool|Yes) = 3/9 = 0.333       # D5,D7,D9

# P(Temperature|Play=No)
P(Hot|No) = 2/5 = 0.400         # D1,D2
P(Mild|No) = 2/5 = 0.400        # D8,D14
P(Cool|No) = 1/5 = 0.200        # D6
```

**Feature: Humidity**

```python
# P(Humidity|Play=Yes)
P(High|Yes) = 3/9 = 0.333       # D3,D4,D12
P(Normal|Yes) = 6/9 = 0.667     # D5,D7,D9,D10,D11,D13

# P(Humidity|Play=No)
P(High|No) = 4/5 = 0.800        # D1,D2,D8,D14
P(Normal|No) = 1/5 = 0.200      # D6
```

**Feature: Wind**

```python
# P(Wind|Play=Yes)
P(Weak|Yes) = 6/9 = 0.667       # D3,D4,D5,D9,D10,D13
P(Strong|Yes) = 3/9 = 0.333     # D7,D11,D12

# P(Wind|Play=No)
P(Weak|No) = 2/5 = 0.400        # D1,D8
P(Strong|No) = 3/5 = 0.600      # D2,D6,D14
```

#### BÆ°á»›c 3: Dá»± Ä‘oÃ¡n cho sample má»›i

**Test case: [Outlook=Sunny, Temperature=Cool, Humidity=High, Wind=Strong]**

```python
# TÃ­nh P(Yes|features)
P(Yes|features) = P(Yes) Ã— P(Sunny|Yes) Ã— P(Cool|Yes) Ã— P(High|Yes) Ã— P(Strong|Yes)
                = 0.643 Ã— 0.222 Ã— 0.333 Ã— 0.333 Ã— 0.333
                = 0.006

# TÃ­nh P(No|features)
P(No|features) = P(No) Ã— P(Sunny|No) Ã— P(Cool|No) Ã— P(High|No) Ã— P(Strong|No)
               = 0.357 Ã— 0.600 Ã— 0.200 Ã— 0.800 Ã— 0.600
               = 0.021

# Káº¿t luáº­n: P(No) > P(Yes) â†’ Prediction: No
```

### ğŸ¯ **Káº¾T QUáº¢ CUá»I CÃ™NG NAIVE BAYES:**

```
ğŸ“Š Báº¢NG XÃC SUáº¤T LIKELIHOOD:

ğŸŒ¤ï¸ OUTLOOK:
       | Yes     | No
-------|---------|--------
Sunny  | 0.222   | 0.600
Overcast| 0.444  | 0.000
Rainy  | 0.333   | 0.400

ğŸŒ¡ï¸ TEMPERATURE:
       | Yes     | No
-------|---------|--------
Hot    | 0.222   | 0.400
Mild   | 0.444   | 0.400
Cool   | 0.333   | 0.200

ğŸ’§ HUMIDITY:
       | Yes     | No
-------|---------|--------
High   | 0.333   | 0.800
Normal | 0.667   | 0.200

ğŸ’¨ WIND:
       | Yes     | No
-------|---------|--------
Weak   | 0.667   | 0.400
Strong | 0.333   | 0.600

ğŸ¯ PRIOR PROBABILITIES:
- P(Yes) = 0.643
- P(No) = 0.357

ğŸ’¡ INSIGHTS:
- Overcast â†’ 100% chÆ¡i tennis (P(Overcast|No) = 0)
- High Humidity â†’ thiÃªn vá» khÃ´ng chÆ¡i (P(High|No) = 0.8)
- Weak Wind â†’ thiÃªn vá» chÆ¡i (P(Weak|Yes) = 0.667)
- Model accuracy trÃªn training data: ~93% (13/14 correct)

ğŸ”® LUáº¬T Dá»° ÄOÃN Máº NH:
1. IF Outlook = Overcast â†’ Cháº¯c cháº¯n Play = Yes
2. IF Humidity = High AND Outlook = Sunny â†’ ThiÃªn vá» Play = No
3. IF Wind = Weak AND Humidity = Normal â†’ ThiÃªn vá» Play = Yes
```

**Gaussian Naive Bayes:**

```
P(xáµ¢|c) = (1/âˆš(2Ï€ÏƒÂ²c)) Ã— exp(-(xáµ¢-Î¼c)Â²/(2ÏƒÂ²c))
```

**Multinomial Naive Bayes:**

```
P(xáµ¢|c) = (Náµ¢c + Î±) / (Nc + Î±|V|)
```

---

# 5. K-MEANS - PHÃ‚N Cá»¤M

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### K-Means lÃ  gÃ¬?

NhÆ° viá»‡c chia há»c sinh thÃ nh cÃ¡c nhÃ³m dá»±a trÃªn Ä‘iá»ƒm sá»‘!

**VÃ­ dá»¥: Chia khÃ¡ch hÃ ng thÃ nh 3 nhÃ³m**

```
ğŸ‘¥ NhÃ³m 1: KhÃ¡ch hÃ ng VIP (thu nháº­p cao, mua nhiá»u)
ğŸ‘¥ NhÃ³m 2: KhÃ¡ch hÃ ng thÆ°á»ng (thu nháº­p trung bÃ¬nh)
ğŸ‘¥ NhÃ³m 3: KhÃ¡ch hÃ ng má»›i (thu nháº­p tháº¥p, Ã­t mua)
```

### CÃ¡ch hoáº¡t Ä‘á»™ng (nhÆ° chÆ¡i game):

1. **ğŸ¯ Äáº·t K tÃ¢m cá»¥m ngáº«u nhiÃªn** (K = 3 tÃ¢m)
2. **ğŸ‘¥ GÃ¡n má»—i ngÆ°á»i vÃ o nhÃ³m gáº§n nháº¥t**
3. **ğŸ“ Di chuyá»ƒn tÃ¢m vá» giá»¯a nhÃ³m**
4. **ğŸ”„ Láº·p láº¡i** cho Ä‘áº¿n khi á»•n Ä‘á»‹nh

### Minh há»a trá»±c quan vá»›i dá»¯ liá»‡u tranh:

```
**ğŸ”¸ Sá»­ dá»¥ng dá»¯ liá»‡u tá»« file `data_k-means_kohonen.csv`:**

Initial data: CÃ¡c bá»©c tranh vá»›i Ä‘áº·c trÆ°ng [MÃ u, NÃ©t, Khá»‘i]

BÆ°á»›c 1: Random centroids     BÆ°á»›c 2: Assign to clusters
    T1[16,124,19]  â€¢â€¢â€¢          C1{T1,T2,T3,T5} â€¢ â€¢ â€¢
  â€¢  T2[6,13,70]    â€¢             â€¢           â—‹
T3[10,22,59] â€¢    T5[21,97,23]    â€¢   C2{T4,T6} â—‹ â—‹
    â€¢ T4[5,81,92]  â€¢              â€¢           â—‹
      T6[7,94,88] â€¢                            â—‹

BÆ°á»›c 3: Update centroids     Final result:
  C1_new[13.25,64,37.75] â€¢       "Abstract Art" â€¢ â€¢ â€¢
     â€¢         â€¢                      â€¢
     â€¢   C2_new[6,87.5,90] â—‹           â€¢
     â€¢         â—‹               "Geometric Art" â—‹ â—‹
               â—‹                              â—‹
```

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Objective Function:

K-Means tá»‘i thiá»ƒu hÃ³a **Within-Cluster Sum of Squares (WCSS)**:

```
J = âˆ‘âˆ‘ ||xáµ¢ - Î¼â±¼||Â²
    j=1 iâˆˆCâ±¼
```

### Thuáº­t toÃ¡n Lloyd:

```python
def kmeans(X, k, max_iters=100):
    # Initialize centroids randomly
    centroids = initialize_random(X, k)

    for iteration in range(max_iters):
        # Assignment step
        clusters = assign_points_to_centroids(X, centroids)

        # Update step
        new_centroids = compute_centroids(clusters)

        # Check convergence
        if converged(centroids, new_centroids):
            break

        centroids = new_centroids

    return clusters, centroids
```

### Äá»™ phá»©c táº¡p:

- **Time**: O(n Ã— k Ã— i Ã— d)
  - n: sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u
  - k: sá»‘ cá»¥m
  - i: sá»‘ iteration
  - d: sá»‘ chiá»u

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Chuáº©n bá»‹ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u

**ğŸ”¸ VÃ­ dá»¥ thá»±c táº¿ tá»« file `data_k-means_kohonen.csv` (Art Dataset):**

```python
# Dá»¯ liá»‡u gá»‘c - PhÃ¢n tÃ­ch cÃ¡c bá»©c tranh qua 3 Ä‘áº·c trÆ°ng
Original Data:
ID | Sá»‘ mÃ u | Sá»‘ Ä‘Æ°á»ng nÃ©t | Sá»‘ hÃ¬nh khá»‘i
1  | 16     | 124         | 19
2  | 6      | 13          | 70
3  | 10     | 22          | 59
4  | 5      | 81          | 92
5  | 21     | 97          | 23
6  | 7      | 94          | 88

# Chuáº©n hÃ³a báº±ng MinMaxScaler (0-1)
Scaled Data:
ID | Sá»‘ mÃ u | Sá»‘ Ä‘Æ°á»ng nÃ©t | Sá»‘ hÃ¬nh khá»‘i
1  | 0.688  | 1.000       | 0.000
2  | 0.063  | 0.000       | 0.699
3  | 0.313  | 0.081       | 0.562
4  | 0.000  | 0.611       | 1.000
5  | 1.000  | 0.757       | 0.055
6  | 0.125  | 0.729       | 0.945
```

#### BÆ°á»›c 2: Khá»Ÿi táº¡o K centroids ngáº«u nhiÃªn

```python
K = 2  # Chia tranh thÃ nh 2 nhÃ³m phong cÃ¡ch
# Initial centroids (random)
C1 = [0.4, 0.5, 0.3]  # Centroid 1
C2 = [0.8, 0.2, 0.7]  # Centroid 2
```

#### BÆ°á»›c 3: Assignment Step (Iteration 1)

```python
# TÃ­nh khoáº£ng cÃ¡ch Euclidean tá»« má»—i tranh Ä‘áº¿n centroids

Tranh 1: [0.688, 1.000, 0.000]
- dist_to_C1 = âˆš[(0.688-0.4)Â² + (1.0-0.5)Â² + (0.0-0.3)Â²] = 0.625
- dist_to_C2 = âˆš[(0.688-0.8)Â² + (1.0-0.2)Â² + (0.0-0.7)Â²] = 1.081
â†’ Assign to Cluster 1

Tranh 2: [0.063, 0.000, 0.699]
- dist_to_C1 = âˆš[(0.063-0.4)Â² + (0.0-0.5)Â² + (0.699-0.3)Â²] = 0.694
- dist_to_C2 = âˆš[(0.063-0.8)Â² + (0.0-0.2)Â² + (0.699-0.7)Â²] = 0.762
â†’ Assign to Cluster 1

Tranh 3: [0.313, 0.081, 0.562]
- dist_to_C1 = âˆš[(0.313-0.4)Â² + (0.081-0.5)Â² + (0.562-0.3)Â²] = 0.511
- dist_to_C2 = âˆš[(0.313-0.8)Â² + (0.081-0.2)Â² + (0.562-0.7)Â²] = 0.550
â†’ Assign to Cluster 1

# Káº¿t quáº£ Iteration 1:
Cluster 1: [Tranh 1, 2, 3, 4, 5]
Cluster 2: [Tranh 6]
```

#### BÆ°á»›c 4: Update Step (Iteration 1)

```python
# TÃ­nh centroid má»›i = trung bÃ¬nh cá»§a cÃ¡c Ä‘iá»ƒm trong cluster

Cluster 1 (Tranh 1,2,3,4,5):
new_C1 = mean([[0.688,1.000,0.000], [0.063,0.000,0.699],
               [0.313,0.081,0.562], [0.000,0.611,1.000],
               [1.000,0.757,0.055]])
new_C1 = [0.413, 0.490, 0.463]

Cluster 2 (Tranh 6):
new_C2 = [0.125, 0.729, 0.945]
```

#### BÆ°á»›c 5: Assignment Step (Iteration 2)

```python
# DÃ¹ng centroids má»›i Ä‘á»ƒ gÃ¡n láº¡i

Vá»›i new_C1=[0.413, 0.490, 0.463], new_C2=[0.125, 0.729, 0.945]:

Tranh 4: [0.000, 0.611, 1.000]
- dist_to_new_C1 = 0.605
- dist_to_new_C2 = 0.150
â†’ Reassign to Cluster 2!

# Káº¿t quáº£ Iteration 2:
Cluster 1: [Tranh 1, 2, 3, 5]
Cluster 2: [Tranh 4, 6]
```

#### BÆ°á»›c 6: Update Step (Iteration 2)

```python
# Update centroids again
final_C1 = [0.516, 0.460, 0.329]  # Mean of Tranh 1,2,3,5
final_C2 = [0.063, 0.670, 0.973]  # Mean of Tranh 4,6

# Kiá»ƒm tra há»™i tá»¥ - centroids thay Ä‘á»•i < threshold â†’ STOP
```

### ğŸ¯ **Káº¾T QUáº¢ CUá»I CÃ™NG K-MEANS:**

```
ğŸ“Š PHÃ‚N Cá»¤M TRANH NGHá»† THUáº¬T (K=2):

ğŸ¨ CLUSTER 1 - "Tranh phá»©c táº¡p, nhiá»u mÃ u":
- Tranh 1: [16 mÃ u, 124 nÃ©t, 19 khá»‘i] â†’ Phong cÃ¡ch phá»©c táº¡p
- Tranh 2: [6 mÃ u, 13 nÃ©t, 70 khá»‘i] â†’ Tá»‘i giáº£n nhÆ°ng nhiá»u khá»‘i
- Tranh 3: [10 mÃ u, 22 nÃ©t, 59 khá»‘i] â†’ CÃ¢n báº±ng
- Tranh 5: [21 mÃ u, 97 nÃ©t, 23 khá»‘i] â†’ Ráº¥t nhiá»u mÃ u vÃ  nÃ©t

ğŸ–¼ï¸ CLUSTER 2 - "Tranh Ä‘Æ¡n giáº£n, Ã­t mÃ u":
- Tranh 4: [5 mÃ u, 81 nÃ©t, 92 khá»‘i] â†’ Ãt mÃ u nhÆ°ng nhiá»u hÃ¬nh khá»‘i
- Tranh 6: [7 mÃ u, 94 nÃ©t, 88 khá»‘i] â†’ TÆ°Æ¡ng tá»± tranh 4

ğŸ“ˆ CENTROIDS CUá»I CÃ™NG:
- Cluster 1: [0.516, 0.460, 0.329] (Nhiá»u mÃ u, Ã­t khá»‘i)
- Cluster 2: [0.063, 0.670, 0.973] (Ãt mÃ u, nhiá»u khá»‘i)

ğŸ“Š WCSS = 0.847 (tá»•ng Ä‘á»™ lá»‡ch trong cluster)

ğŸ’¡ INSIGHTS:
- Tranh Ä‘Æ°á»£c nhÃ³m chá»§ yáº¿u theo sá»‘ lÆ°á»£ng hÃ¬nh khá»‘i
- Cluster 1: Táº­p trung vÃ o sá»± Ä‘a dáº¡ng mÃ u sáº¯c vÃ  Ä‘Æ°á»ng nÃ©t
- Cluster 2: Táº­p trung vÃ o hÃ¬nh khá»‘i, Ã­t quan tÃ¢m mÃ u sáº¯c
- CÃ³ thá»ƒ mÃ´ táº£ nhÆ° "Abstract Art" vs "Geometric Art"
```

### CÃ¡ch chá»n K:

1. **Elbow Method**: TÃ¬m "khuá»·u tay" trÃªn Ä‘á»“ thá»‹ WCSS

   ```python
   # Cháº¡y K-Means vá»›i K = 1,2,3,4,5...
   # Plot WCSS vs K
   # Chá»n K táº¡i Ä‘iá»ƒm "elbow" (giáº£m cháº­m láº¡i)
   ```

2. **Silhouette Analysis**: Äo Ä‘á»™ tÃ¡ch biá»‡t cá»§a cÃ¡c cá»¥m

   ```python
   # Silhouette score tá»« -1 Ä‘áº¿n 1
   # Score cao = clusters tÃ¡ch biá»‡t tá»‘t
   # Chá»n K cÃ³ silhouette score cao nháº¥t
   ```

3. **Gap Statistic**: So sÃ¡nh vá»›i phÃ¢n phá»‘i ngáº«u nhiÃªn
   ```python
   # So sÃ¡nh WCSS thá»±c táº¿ vs WCSS cá»§a dá»¯ liá»‡u random
   # Chá»n K cÃ³ gap lá»›n nháº¥t
   ```

---

# 6. KOHONEN SOM - Báº¢N Äá»’ Tá»° Tá»” CHá»¨C

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### SOM lÃ  gÃ¬?

NhÆ° viá»‡c váº½ báº£n Ä‘á»“ tháº¿ giá»›i trÃªn giáº¥y pháº³ng! Biáº¿n dá»¯ liá»‡u phá»©c táº¡p nhiá»u chiá»u thÃ nh báº£n Ä‘á»“ 2D dá»… nhÃ¬n.

**VÃ­ dá»¥ thá»±c táº¿:**

```
ğŸµ PhÃ¢n loáº¡i nháº¡c:
- GÃ³c trÃªn trÃ¡i: Rock, Metal
- GÃ³c trÃªn pháº£i: Classical, Jazz
- GÃ³c dÆ°á»›i trÃ¡i: Pop, Dance
- GÃ³c dÆ°á»›i pháº£i: Country, Folk

â†’ Nháº¡c tÆ°Æ¡ng tá»± sáº½ á»Ÿ gáº§n nhau trÃªn báº£n Ä‘á»“!
```

### Táº¡i sao há»¯u Ã­ch?

- ğŸ‘ï¸ **Trá»±c quan hÃ³a**: Tháº¥y Ä‘Æ°á»£c pattern trong dá»¯ liá»‡u
- ğŸ—ºï¸ **Giáº£m chiá»u**: Tá»« 100 thuá»™c tÃ­nh â†’ báº£n Ä‘á»“ 2D
- ğŸ” **TÃ¬m nhÃ³m**: CÃ¡c vÃ¹ng tÆ°Æ¡ng tá»± nhau

### CÃ¡ch hoáº¡t Ä‘á»™ng (nhÆ° há»c báº£n Ä‘á»“):

1. **ğŸ—ºï¸ Táº¡o lÆ°á»›i trá»‘ng** (nhÆ° báº£n Ä‘á»“ tráº¯ng)
2. **ğŸ“ Äáº·t dá»¯ liá»‡u lÃªn lÆ°á»›i** (má»—i Ä‘iá»ƒm tÃ¬m vá»‹ trÃ­ phÃ¹ há»£p)
3. **ğŸ”„ Äiá»u chá»‰nh dáº§n** (vÃ¹ng xung quanh cÅ©ng thay Ä‘á»•i)
4. **âœ… HoÃ n thÃ nh báº£n Ä‘á»“** (dá»¯ liá»‡u tÆ°Æ¡ng tá»± á»Ÿ gáº§n nhau)

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Cáº¥u trÃºc SOM:

- **Input Layer**: Vector Ä‘áº§u vÃ o x âˆˆ â„â¿
- **Output Layer**: LÆ°á»›i 2D cÃ¡c neuron vá»›i weight vector wáµ¢â±¼ âˆˆ â„â¿

### Thuáº­t toÃ¡n training:

**1. TÃ¬m Best Matching Unit (BMU):**

```
c = argmin ||x(t) - wáµ¢â±¼(t)||
    i,j
```

**2. Update weights:**

```
wáµ¢â±¼(t+1) = wáµ¢â±¼(t) + Î±(t) Ã— h(c,i,j,t) Ã— [x(t) - wáµ¢â±¼(t)]
```

**3. Neighborhood function:**

```
h(c,i,j,t) = exp(-||rc - ráµ¢â±¼||Â² / (2Ïƒ(t)Â²))
```

**4. Learning rate decay:**

```
Î±(t) = Î±â‚€ Ã— exp(-t/Ï„â‚)
Ïƒ(t) = Ïƒâ‚€ Ã— exp(-t/Ï„â‚‚)
```

### Pseudocode:

```python
def train_som(data, map_size, epochs):
    # Initialize weight vectors randomly
    weights = initialize_weights(map_size, input_dim)

    for epoch in range(epochs):
        for x in data:
            # Find BMU
            bmu = find_best_matching_unit(x, weights)

            # Update weights in neighborhood
            for i, j in map_coordinates:
                distance = euclidean_distance(bmu, (i,j))
                if distance <= neighborhood_radius(epoch):
                    influence = neighborhood_function(distance, epoch)
                    learning_rate = get_learning_rate(epoch)

                    weights[i][j] += learning_rate * influence * (x - weights[i][j])

    return weights
```

---

# ğŸ“Š SO SÃNH CÃC THUáº¬T TOÃN

| Thuáº­t toÃ¡n        | Loáº¡i           | á»¨ng dá»¥ng chÃ­nh        | Æ¯u Ä‘iá»ƒm           | NhÆ°á»£c Ä‘iá»ƒm           |
| ----------------- | -------------- | --------------------- | ----------------- | -------------------- |
| **Apriori**       | Association    | Basket Analysis       | TÃ¬m pattern áº©n    | Cháº­m vá»›i dá»¯ liá»‡u lá»›n |
| **Rough Set**     | Classification | Feature Selection     | Xá»­ lÃ½ uncertainty | Phá»©c táº¡p tÃ­nh toÃ¡n   |
| **Decision Tree** | Classification | Rule Extraction       | Dá»… hiá»ƒu           | Dá»… overfitting       |
| **Naive Bayes**   | Classification | Text Classification   | Nhanh, Ä‘Æ¡n giáº£n   | Giáº£ Ä‘á»‹nh Ä‘á»™c láº­p     |
| **K-Means**       | Clustering     | Customer Segmentation | ÄÆ¡n giáº£n, nhanh   | Cáº§n biáº¿t trÆ°á»›c K     |
| **SOM**           | Visualization  | Data Exploration      | Trá»±c quan hÃ³a tá»‘t | KhÃ³ diá»…n giáº£i        |

---

# ğŸ¯ Káº¾T LUáº¬N

Má»—i thuáº­t toÃ¡n cÃ³ Ä‘iá»ƒm máº¡nh riÃªng:

- **ğŸ›’ Muá»‘n tÃ¬m pattern mua hÃ ng** â†’ DÃ¹ng **Apriori**
- **ğŸ¯ Muá»‘n phÃ¢n loáº¡i chÃ­nh xÃ¡c** â†’ DÃ¹ng **Decision Tree** hoáº·c **Naive Bayes**
- **ğŸ‘¥ Muá»‘n chia nhÃ³m khÃ¡ch hÃ ng** â†’ DÃ¹ng **K-Means**
- **ğŸ—ºï¸ Muá»‘n khÃ¡m phÃ¡ dá»¯ liá»‡u** â†’ DÃ¹ng **SOM**
- **âš–ï¸ Muá»‘n loáº¡i bá» thuá»™c tÃ­nh thá»«a** â†’ DÃ¹ng **Rough Set**

**Lá»i khuyÃªn:** HÃ£y thá»­ nhiá»u thuáº­t toÃ¡n vÃ  so sÃ¡nh káº¿t quáº£ Ä‘á»ƒ chá»n phÆ°Æ¡ng phÃ¡p phÃ¹ há»£p nháº¥t!

---

# 7. HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG APP

## ğŸš€ Khá»Ÿi cháº¡y á»©ng dá»¥ng

### CÃ¡ch 1: Sá»­ dá»¥ng file batch (Windows)

```bash
# Double-click file run_demo.bat
# Hoáº·c cháº¡y trong command prompt:
run_demo.bat
```

### CÃ¡ch 2: Sá»­ dá»¥ng terminal

```bash
# CÃ i Ä‘áº·t dependencies (chá»‰ cáº§n lÃ m 1 láº§n)
pip install streamlit pandas numpy matplotlib seaborn scikit-learn mlxtend minisom graphviz

# Cháº¡y app
streamlit run app.py
```

## ğŸ“Š Quy trÃ¬nh sá»­ dá»¥ng tá»«ng thuáº­t toÃ¡n

### 1ï¸âƒ£ **APRIORI - Luáº­t káº¿t há»£p**

#### BÆ°á»›c 1: Upload dá»¯ liá»‡u

- Táº£i file CSV cÃ³ dá»¯ liá»‡u giao dá»‹ch
- VD: Cá»™t "TransactionID" vÃ  "Product"

#### BÆ°á»›c 2: Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½

```
ğŸ”¹ One-hot encode: Cho dá»¯ liá»‡u giao dá»‹ch chuáº©n
   - Chá»n 2 cá»™t: [TransactionID, Product]

ğŸ”¹ Dá»¯ liá»‡u sá»‘ gá»‘c: Cho dá»¯ liá»‡u Ä‘Ã£ á»Ÿ dáº¡ng 0/1

ğŸ”¹ Chuyá»ƒn boolean: Cho dá»¯ liá»‡u há»—n há»£p
```

#### BÆ°á»›c 3: Thiáº¿t láº­p tham sá»‘

- **Support**: 0.1-0.5 (thÆ°á»ng dÃ¹ng 0.3)
- **Confidence**: 0.5-0.8 (thÆ°á»ng dÃ¹ng 0.6)

#### BÆ°á»›c 4: PhÃ¢n tÃ­ch káº¿t quáº£

```
âœ… Táº­p phá»• biáº¿n: CÃ¡c item xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn
âœ… Táº­p tá»‘i Ä‘áº¡i: Táº­p phá»• biáº¿n khÃ´ng chá»©a trong táº­p nÃ o lá»›n hÆ¡n
âœ… Luáº­t káº¿t há»£p: If A then B vá»›i confidence
```

---

### 2ï¸âƒ£ **ROUGH SET - Táº­p thÃ´**

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

- Äáº£m báº£o cÃ³ cá»™t káº¿t quáº£ rÃµ rÃ ng
- Dá»¯ liá»‡u categorical hoáº·c Ä‘Ã£ rá»i ráº¡c hÃ³a

#### BÆ°á»›c 2: Chá»n thuá»™c tÃ­nh

```
ğŸ¯ Thuá»™c tÃ­nh quyáº¿t Ä‘á»‹nh: Cá»™t káº¿t quáº£ (VD: "Buy")
ğŸ“Š Thuá»™c tÃ­nh Ä‘iá»u kiá»‡n: CÃ¡c cá»™t Ä‘áº·c trÆ°ng (VD: "Age", "Income")
```

#### BÆ°á»›c 3: Chá»n lá»›p má»¥c tiÃªu

- Chá»n giÃ¡ trá»‹ cá»¥ thá»ƒ cáº§n phÃ¢n tÃ­ch (VD: "Yes")

#### BÆ°á»›c 4: Äá»c káº¿t quáº£

```
ğŸ“ Xáº¥p xá»‰ dÆ°á»›i: Cháº¯c cháº¯n thuá»™c lá»›p
ğŸ“ Xáº¥p xá»‰ trÃªn: CÃ³ thá»ƒ thuá»™c lá»›p
ğŸ“Š Äá»™ chÃ­nh xÃ¡c: Tá»· lá»‡ dÆ°á»›i/trÃªn
ğŸ”§ RÃºt gá»n: Thuá»™c tÃ­nh tá»‘i thiá»ƒu cáº§n thiáº¿t
```

---

### 3ï¸âƒ£ **DECISION TREE - CÃ¢y quyáº¿t Ä‘á»‹nh**

#### BÆ°á»›c 1: Chá»n thuá»™c tÃ­nh

```
ğŸ¯ Thuá»™c tÃ­nh má»¥c tiÃªu: Cá»™t cáº§n dá»± Ä‘oÃ¡n
ğŸ“Š Thuá»™c tÃ­nh Ä‘áº§u vÃ o: CÃ¡c cá»™t Ä‘áº·c trÆ°ng
```

#### BÆ°á»›c 2: Chá»n phÆ°Æ¡ng phÃ¡p

- **Gain (Entropy)**: Cho dá»¯ liá»‡u cÃ¢n báº±ng
- **Gini Gain**: Cho dá»¯ liá»‡u lá»›n, cáº§n tá»‘c Ä‘á»™

#### BÆ°á»›c 3: PhÃ¢n tÃ­ch káº¿t quáº£

```
ğŸŒ³ Biá»ƒu Ä‘á»“ cÃ¢y: Visualization dá»… hiá»ƒu
ğŸ“‹ Luáº­t rÃºt ra: Dáº¡ng IF-THEN
ğŸ“Š Äiá»ƒm thuá»™c tÃ­nh: Information Gain/Gini cá»§a tá»«ng feature
```

---

### 4ï¸âƒ£ **NAIVE BAYES - PhÃ¢n loáº¡i xÃ¡c suáº¥t**

#### BÆ°á»›c 1: Chá»n cá»™t má»¥c tiÃªu

- Chá»n cá»™t cáº§n phÃ¢n loáº¡i tá»« sidebar

#### BÆ°á»›c 2: Chá»n loáº¡i Naive Bayes

```
ğŸ”¹ GaussianNB: Cho dá»¯ liá»‡u sá»‘ liÃªn tá»¥c
ğŸ”¹ MultinomialNB: Cho dá»¯ liá»‡u Ä‘áº¿m/frequency
   - CÃ i Ä‘áº·t Alpha (Laplace smoothing): 0.1-3.0
   - CÃ³ thá»ƒ cáº§n MinMaxScaler náº¿u cÃ³ giÃ¡ trá»‹ Ã¢m
```

#### BÆ°á»›c 3: Äá»c káº¿t quáº£

```
ğŸ“Š Accuracy: Äá»™ chÃ­nh xÃ¡c trÃªn táº­p training
âš¡ Tá»‘c Ä‘á»™: Ráº¥t nhanh, phÃ¹ há»£p dá»¯ liá»‡u lá»›n
```

---

### 5ï¸âƒ£ **K-MEANS - PhÃ¢n cá»¥m**

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

- KhÃ´ng cáº§n chá»n cá»™t má»¥c tiÃªu
- Sá»­ dá»¥ng táº¥t cáº£ cá»™t sá»‘

#### BÆ°á»›c 2: Chá»n sá»‘ cá»¥m K

- ThÆ°á»ng chá»n 2-5 cá»¥m
- CÃ³ thá»ƒ thá»­ nhiá»u giÃ¡ trá»‹ Ä‘á»ƒ so sÃ¡nh

#### BÆ°á»›c 3: PhÃ¢n tÃ­ch káº¿t quáº£

```
ğŸ“Š Báº£ng gÃ¡n cá»¥m: Má»—i dÃ²ng thuá»™c cá»¥m nÃ o
ğŸ“ˆ Scatter plot: Visualization 2D (náº¿u â‰¥2 thuá»™c tÃ­nh)
ğŸ¯ TÃ¢m cá»¥m: Vá»‹ trÃ­ trung tÃ¢m cá»§a tá»«ng cá»¥m
```

---

### 6ï¸âƒ£ **KOHONEN SOM - Báº£n Ä‘á»“ tá»± tá»• chá»©c**

#### BÆ°á»›c 1: Thiáº¿t láº­p tham sá»‘

```
ğŸ”§ KÃ­ch thÆ°á»›c lÆ°á»›i:
   - Rows: 3-10 (thÆ°á»ng 4)
   - Cols: 3-10 (thÆ°á»ng 4)

ğŸšï¸ Tham sá»‘ training:
   - Sigma: 0.5-2.0 (thÆ°á»ng 1.0)
   - Learning Rate: 0.1-0.8 (thÆ°á»ng 0.5)
   - Iterations: 100-1000 (thÆ°á»ng 500)
```

#### BÆ°á»›c 2: Äá»c káº¿t quáº£

```
ğŸ—ºï¸ Hit Map: MÃ u Ä‘áº­m = nhiá»u data points
ğŸ“Š Class Maps: PhÃ¢n bá»‘ tá»«ng lá»›p trÃªn báº£n Ä‘á»“
ğŸ” Pattern: VÃ¹ng tÆ°Æ¡ng tá»± gáº§n nhau
```

## ğŸ¯ TIPS Sá»¬ Dá»¤NG HIá»†U QUáº¢

### âœ… NÃªn lÃ m:

- **Test nhiá»u tham sá»‘**: Thá»­ cÃ¡c giÃ¡ trá»‹ khÃ¡c nhau Ä‘á»ƒ so sÃ¡nh
- **Chuáº©n bá»‹ dá»¯ liá»‡u tá»‘t**: Clean data trÆ°á»›c khi upload
- **Äá»c cáº£nh bÃ¡o**: App cÃ³ thÃ´ng bÃ¡o há»¯u Ã­ch
- **So sÃ¡nh thuáº­t toÃ¡n**: DÃ¹ng nhiá»u phÆ°Æ¡ng phÃ¡p cho cÃ¹ng bÃ i toÃ¡n

### âŒ TrÃ¡nh:

- **Dá»¯ liá»‡u quÃ¡ Ã­t**: <10 dÃ²ng sáº½ khÃ³ phÃ¢n tÃ­ch
- **QuÃ¡ nhiá»u thuá»™c tÃ­nh**: CÃ³ thá»ƒ gÃ¢y overfitting
- **Tham sá»‘ cá»±c Ä‘oan**: Min support = 0.01 hoáº·c 0.99
- **Bá» qua validation**: KhÃ´ng check káº¿t quáº£ cÃ³ há»£p lÃ½

### ğŸ”§ Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p:

**Lá»—i: "File seems to be binary"**

- Upload file CSV, khÃ´ng pháº£i Excel/Word

**Lá»—i: "MultinomialNB khÃ´ng thá»ƒ xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m"**

- TÃ­ch chá»n "Ãp dá»¥ng MinMaxScaler"

**Cáº£nh bÃ¡o: "Cá»™t cÃ³ nhiá»u giÃ¡ trá»‹ duy nháº¥t"**

- CÃ¢n nháº¯c rá»i ráº¡c hÃ³a cho Rough Set

**KhÃ´ng cÃ³ káº¿t quáº£ Apriori**

- Giáº£m min_support xuá»‘ng 0.1-0.2

---

## ğŸ“‹ CHECKLIST TRÆ¯á»šC KHI Sá»¬ Dá»¤NG

- [ ] ÄÃ£ cÃ i Ä‘áº·t Python vÃ  pip
- [ ] ÄÃ£ install cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
- [ ] File dá»¯ liá»‡u á»Ÿ Ä‘á»‹nh dáº¡ng CSV
- [ ] Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch (khÃ´ng quÃ¡ nhiá»u missing values)
- [ ] Hiá»ƒu rÃµ má»¥c tiÃªu phÃ¢n tÃ­ch
- [ ] Äá»c ká»¹ hÆ°á»›ng dáº«n thuáº­t toÃ¡n tÆ°Æ¡ng á»©ng

---

_ğŸ“š TÃ i liá»‡u nÃ y Ä‘Æ°á»£c táº¡o Ä‘á»ƒ há»— trá»£ há»c táº­p mÃ´n Khai thÃ¡c Dá»¯ liá»‡u. ChÃºc báº¡n há»c tá»‘t! ğŸš€_
