# ğŸ“š HÆ¯á»šNG DáºªN CÃC THUáº¬T TOÃN KHAI THÃC Dá»® LIá»†U

## ğŸ“‹ Má»¥c lá»¥c

1. [Apriori - Luáº­t Káº¿t Há»£p](#1-apriori---luáº­t-káº¿t-há»£p)
2. [Rough Set - LÃ½ Thuyáº¿t Táº­p ThÃ´](#2-rough-set---lÃ½-thuyáº¿t-táº­p-thÃ´)
3. [Decision Tree ID3 - CÃ¢y Quyáº¿t Äá»‹nh](#3-decision-tree-id3---cÃ¢y-quyáº¿t-Ä‘á»‹nh)
4. [Naive Bayes - PhÃ¢n Loáº¡i XÃ¡c Suáº¥t](#4-naive-bayes---phÃ¢n-loáº¡i-xÃ¡c-suáº­t)
5. [K-Means - PhÃ¢n Cá»¥m](#5-k-means---phÃ¢n-cá»¥m)
6. [Kohonen SOM - Báº£n Äá»“ Tá»± Tá»• Chá»©c](#6-kohonen-som---báº£n-Ä‘á»“-tá»±-tá»•-chá»©c)
7. [HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng App](#7-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng-app)

## ğŸš€ Giá»›i thiá»‡u dá»± Ã¡n

ÄÃ¢y lÃ  á»©ng dá»¥ng **Streamlit** triá»ƒn khai 6 thuáº­t toÃ¡n khai thÃ¡c dá»¯ liá»‡u chÃ­nh vá»›i giao diá»‡n tÆ°Æ¡ng tÃ¡c thÃ¢n thiá»‡n. Má»—i thuáº­t toÃ¡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c bÃ i toÃ¡n khÃ¡c nhau trong phÃ¢n tÃ­ch dá»¯ liá»‡u.

### ğŸ“ Cáº¥u trÃºc dá»± Ã¡n:

```
ğŸ“‚ Dá»± Ã¡n Data Mining
â”œâ”€â”€ ğŸ“„ app.py              # Giao diá»‡n Streamlit chÃ­nh
â”œâ”€â”€ ğŸ“„ func.py             # Logic thuáº­t toÃ¡n
â”œâ”€â”€ ğŸ“„ sample_data.csv     # Dá»¯ liá»‡u máº«u
â”œâ”€â”€ ğŸ“„ run_demo.bat        # Script khá»Ÿi cháº¡y
â”œâ”€â”€ ğŸ“„ DEMO_CHEATSHEET.md  # Tham kháº£o demo
â””â”€â”€ ğŸ“„ readme.md           # TÃ i liá»‡u nÃ y
```

---

# 1. APRIORI - LUáº¬T Káº¾T Há»¢P

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Apriori lÃ  gÃ¬?

HÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n lÃ  chá»§ siÃªu thá»‹ vÃ  muá»‘n biáº¿t khÃ¡ch hÃ ng thÆ°á»ng mua nhá»¯ng gÃ¬ cÃ¹ng nhau!

**VÃ­ dá»¥ Ä‘á»i thÆ°á»ng:**

```
ğŸ›’ Giá» hÃ ng 1: BÃ¡nh mÃ¬ + Sá»¯a + BÆ¡
ğŸ›’ Giá» hÃ ng 2: BÃ¡nh mÃ¬ + Sá»¯a
ğŸ›’ Giá» hÃ ng 3: Sá»¯a + PhÃ´ mai
ğŸ›’ Giá» hÃ ng 4: BÃ¡nh mÃ¬ + Sá»¯a + PhÃ´ mai
```

**Apriori sáº½ tÃ¬m ra:**

- "Náº¿u ai mua **BÃ¡nh mÃ¬** thÃ¬ **80%** cÅ©ng mua **Sá»¯a**"
- "Náº¿u ai mua **Sá»¯a** vÃ  **BÃ¡nh mÃ¬** thÃ¬ **60%** cÅ©ng mua **BÆ¡**"

### Táº¡i sao quan trá»ng?

- ğŸ¯ **Bá»‘ trÃ­ hÃ ng hÃ³a**: Äáº·t sá»¯a gáº§n bÃ¡nh mÃ¬
- ğŸ“ˆ **Khuyáº¿n mÃ£i**: Giáº£m giÃ¡ combo bÃ¡nh mÃ¬ + sá»¯a
- ğŸ’¡ **Gá»£i Ã½ mua hÃ ng**: "KhÃ¡ch hÃ ng Ä‘Ã£ mua bÃ¡nh mÃ¬, cÃ³ thá»ƒ thÃ­ch sá»¯a"

### CÃ¡c khÃ¡i niá»‡m Ä‘Æ¡n giáº£n:

- **Support (Há»— trá»£)**: CÃ³ bao nhiá»u % khÃ¡ch hÃ ng mua item nÃ y?
  - VD: 70% khÃ¡ch mua bÃ¡nh mÃ¬ â†’ Support(BÃ¡nh mÃ¬) = 0.7
- **Confidence (Tin cáº­y)**: Náº¿u mua A thÃ¬ kháº£ nÄƒng mua B lÃ  bao nhiá»u?
  - VD: Trong sá»‘ ngÆ°á»i mua bÃ¡nh mÃ¬, 80% cÅ©ng mua sá»¯a â†’ Conf(BÃ¡nh mÃ¬ â†’ Sá»¯a) = 0.8

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ“Š TÃ¹y chá»n tiá»n xá»­ lÃ½ dá»¯ liá»‡u:

1. **One-hot encode cÃ¡c cá»™t Ä‘Æ°á»£c chá»n**

   - DÃ¹ng cho dá»¯ liá»‡u giao dá»‹ch (TransactionID, Product)
   - Chuyá»ƒn categorical data thÃ nh dáº¡ng binary matrix
   - **Khi nÃ o dÃ¹ng**: CÃ³ dá»¯ liá»‡u dáº¡ng giao dá»‹ch rÃµ rÃ ng

2. **Sá»­ dá»¥ng cÃ¡c cá»™t sá»‘ gá»‘c**

   - DÃ¹ng trá»±c tiáº¿p dá»¯ liá»‡u sá»‘
   - **LÆ°u Ã½**: Chá»‰ phÃ¹ há»£p khi dá»¯ liá»‡u Ä‘Ã£ á»Ÿ dáº¡ng 0/1

3. **Chuyá»ƒn Ä‘á»•i toÃ n bá»™ sang boolean**
   - Biáº¿n táº¥t cáº£ thÃ nh True/False
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u há»—n há»£p nhiá»u loáº¡i

### ğŸšï¸ Tham sá»‘ chÃ­nh:

- **Min Support (0.01-1.0)**: Tá»· lá»‡ tá»‘i thiá»ƒu xuáº¥t hiá»‡n cá»§a itemset
  - Tháº¥p (0.1-0.3): Nhiá»u pattern, cÃ³ thá»ƒ nhiá»u noise
  - Cao (0.5-0.8): Ãt pattern, chá»‰ nhá»¯ng máº«u ráº¥t phá»• biáº¿n
- **Min Confidence (0.01-1.0)**: Äá»™ tin cáº­y tá»‘i thiá»ƒu cá»§a luáº­t
  - Tháº¥p (0.3-0.5): Nhiá»u luáº­t, Ä‘á»™ tin cáº­y tháº¥p
  - Cao (0.7-0.9): Ãt luáº­t, Ä‘á»™ tin cáº­y cao

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh nghÄ©a chÃ­nh thá»©c:

Apriori lÃ  thuáº­t toÃ¡n tÃ¬m **frequent itemsets** vÃ  **association rules** tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u giao dá»‹ch.

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

```python
# Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh transaction matrix
# VD: DataFrame â†’ Binary Matrix
TransactionID | Product  â†’  Bread | Milk | Butter
T001         | Bread       1    | 0    | 0
T001         | Milk        1    | 1    | 0
T002         | Butter      0    | 0    | 1
```

#### BÆ°á»›c 2: TÃ¬m Frequent 1-itemsets (Lâ‚)

```python
# Äáº¿m frequency cá»§a tá»«ng item
support(Bread) = 3/4 = 0.75 â‰¥ min_support â†’ Keep
support(Milk) = 2/4 = 0.5 â‰¥ min_support â†’ Keep
support(Butter) = 1/4 = 0.25 < min_support â†’ Remove
```

#### BÆ°á»›c 3: Sinh Candidate 2-itemsets (Câ‚‚)

```python
# Káº¿t há»£p cÃ¡c frequent 1-itemsets
Lâ‚ = {Bread, Milk}
Câ‚‚ = {Bread,Milk}
```

#### BÆ°á»›c 4: TÃ­nh Support vÃ  lá»c â†’ Lâ‚‚

```python
support(Bread,Milk) = 2/4 = 0.5 â‰¥ min_support â†’ Keep
Lâ‚‚ = {Bread,Milk}
```

#### BÆ°á»›c 5: Sinh Association Rules

```python
# Tá»« itemset {Bread,Milk}
Rule 1: Bread â†’ Milk
confidence = support(Bread,Milk)/support(Bread) = 0.5/0.75 = 0.67

Rule 2: Milk â†’ Bread
confidence = support(Bread,Milk)/support(Milk) = 0.5/0.5 = 1.0
```

### CÃ¡c bÆ°á»›c thuáº­t toÃ¡n:

1. **TÃ¬m frequent 1-itemsets** (Lâ‚)
2. **Sinh candidate 2-itemsets** (Câ‚‚) tá»« Lâ‚
3. **TÃ­nh support vÃ  lá»c** â†’ Lâ‚‚
4. **Láº·p láº¡i** cho Ä‘áº¿n khi khÃ´ng cÃ²n frequent itemsets

### CÃ´ng thá»©c toÃ¡n há»c:

**Support:**

```
Support(A) = |T(A)| / |T|
```

Trong Ä‘Ã³: |T(A)| = sá»‘ giao dá»‹ch chá»©a A, |T| = tá»•ng sá»‘ giao dá»‹ch

**Confidence:**

```
Confidence(A â†’ B) = Support(A âˆª B) / Support(A)
```

**Lift:**

```
Lift(A â†’ B) = Support(A âˆª B) / (Support(A) Ã— Support(B))
```

### Pseudocode:

```python
def apriori(transactions, min_support):
    L1 = find_frequent_1_itemsets(transactions, min_support)
    L = [L1]
    k = 2

    while L[k-2] is not empty:
        Ck = apriori_gen(L[k-2])  # Generate candidates
        for transaction in transactions:
            Ct = subset(Ck, transaction)  # Candidates in transaction
            for candidate in Ct:
                candidate.count++

        Lk = {c in Ck | c.support >= min_support}
        L.append(Lk)
        k = k + 1

    return union(L)
```

---

# 2. ROUGH SET - LÃ THUYáº¾T Táº¬P THÃ”

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Rough Set lÃ  gÃ¬?

HÃ£y tÆ°á»Ÿng tÆ°á»£ng báº¡n muá»‘n phÃ¢n loáº¡i há»c sinh "Giá»i" hay "Yáº¿u" dá»±a trÃªn Ä‘iá»ƒm sá»‘, nhÆ°ng cÃ³ má»™t sá»‘ trÆ°á»ng há»£p khÃ´ng rÃµ rÃ ng!

**VÃ­ dá»¥:**

```
Há»c sinh A: ToÃ¡n=8, LÃ½=7, HÃ³a=9 â†’ Giá»i âœ“
Há»c sinh B: ToÃ¡n=5, LÃ½=4, HÃ³a=6 â†’ Yáº¿u âœ“
Há»c sinh C: ToÃ¡n=7, LÃ½=6, HÃ³a=5 â†’ ??? (KhÃ´ng cháº¯c)
```

### Rough Set giÃºp gÃ¬?

- ğŸ¯ **TÃ¬m thuá»™c tÃ­nh quan trá»ng**: MÃ´n nÃ o quyáº¿t Ä‘á»‹nh "Giá»i/Yáº¿u"?
- ğŸ” **Xá»­ lÃ½ khÃ´ng cháº¯c cháº¯n**: PhÃ¢n loáº¡i nhá»¯ng trÆ°á»ng há»£p mÆ¡ há»“
- âœ‚ï¸ **Giáº£m thuá»™c tÃ­nh**: Loáº¡i bá» thÃ´ng tin thá»«a

### CÃ¡c khÃ¡i niá»‡m Ä‘Æ¡n giáº£n:

- **Lower Approximation (Xáº¥p xá»‰ dÆ°á»›i)**: Nhá»¯ng trÆ°á»ng há»£p **CHáº®C CHáº®N** thuá»™c nhÃ³m
- **Upper Approximation (Xáº¥p xá»‰ trÃªn)**: Nhá»¯ng trÆ°á»ng há»£p **CÃ“ THá»‚** thuá»™c nhÃ³m
- **Boundary Region (VÃ¹ng biÃªn)**: Nhá»¯ng trÆ°á»ng há»£p **KHÃ”NG CHáº®C**

### Minh há»a trá»±c quan:

```
ğŸ¯ Má»¥c tiÃªu: PhÃ¢n loáº¡i "Há»c sinh giá»i"

Lower Approximation (Cháº¯c cháº¯n giá»i):
ğŸ‘¨â€ğŸ“ ToÃ¡nâ‰¥8 AND LÃ½â‰¥8 â†’ 100% Giá»i

Upper Approximation (CÃ³ thá»ƒ giá»i):
ğŸ‘¨â€ğŸ“ ToÃ¡nâ‰¥6 OR LÃ½â‰¥6 â†’ CÃ³ thá»ƒ Giá»i

Boundary Region (KhÃ´ng cháº¯c):
ğŸ‘¨â€ğŸ“ 6â‰¤ToÃ¡n<8 AND 6â‰¤LÃ½<8 â†’ Cáº§n xem thÃªm
```

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n thuá»™c tÃ­nh:

- **Thuá»™c tÃ­nh quyáº¿t Ä‘á»‹nh**: Cá»™t chá»©a káº¿t quáº£ cáº§n dá»± Ä‘oÃ¡n (VD: "PhÃ¢n loáº¡i", "Káº¿t quáº£")
- **Thuá»™c tÃ­nh Ä‘iá»u kiá»‡n**: CÃ¡c cá»™t Ä‘áº·c trÆ°ng Ä‘á»ƒ phÃ¢n tÃ­ch (VD: "Äiá»ƒm toÃ¡n", "Äiá»ƒm lÃ½")

### ğŸ† Chá»n lá»›p má»¥c tiÃªu:

- Chá»n giÃ¡ trá»‹ cá»¥ thá»ƒ muá»‘n phÃ¢n tÃ­ch (VD: "Giá»i", "Yáº¿u", "Trung bÃ¬nh")

### ğŸ’¡ LÆ°u Ã½ quan trá»ng:

- **Dá»¯ liá»‡u categorical**: App tá»± Ä‘á»™ng chuyá»ƒn sang string
- **Cáº£nh bÃ¡o rá»i ráº¡c hÃ³a**: Náº¿u cá»™t sá»‘ cÃ³ >15 giÃ¡ trá»‹ unique sáº½ Ä‘Æ°á»£c cáº£nh bÃ¡o

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh nghÄ©a toÃ¡n há»c:

Cho táº­p vÅ© trá»¥ U, quan há»‡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng R, vÃ  táº­p má»¥c tiÃªu X âŠ† U.

**Lower Approximation:**

```
R*(X) = {x âˆˆ U | [x]R âŠ† X}
```

**Upper Approximation:**

```
R*(X) = {x âˆˆ U | [x]R âˆ© X â‰  âˆ…}
```

**Boundary Region:**

```
BND_R(X) = R*(X) - R*(X)
```

### CÃ¡c thÆ°á»›c Ä‘o cháº¥t lÆ°á»£ng:

**Accuracy (Äá»™ chÃ­nh xÃ¡c):**

```
Î±_R(X) = |R*(X)| / |R*(X)|
```

**Dependency (Má»©c Ä‘á»™ phá»¥ thuá»™c):**

```
Î³_R(D) = |POS_R(D)| / |U|
```

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: XÃ¢y dá»±ng Information Table

```
| ID | ToÃ¡n | LÃ½ | HÃ³a | Káº¿t quáº£ |
|----|------|----|----|---------|
| 1  | 8    | 9  | 7  | Giá»i    |
| 2  | 6    | 7  | 8  | Giá»i    |
| 3  | 4    | 5  | 6  | Yáº¿u     |
| 4  | 7    | 6  | 7  | ?       |
```

#### BÆ°á»›c 2: Táº¡o Equivalence Classes

```python
# NhÃ³m theo thuá»™c tÃ­nh Ä‘iá»u kiá»‡n [ToÃ¡n, LÃ½]
Class 1: {ID1} â†’ [8,9] â†’ Giá»i
Class 2: {ID2} â†’ [6,7] â†’ Giá»i
Class 3: {ID3} â†’ [4,5] â†’ Yáº¿u
Class 4: {ID4} â†’ [7,6] â†’ ?
```

#### BÆ°á»›c 3: TÃ­nh Lower Approximation

```python
# TÃ¬m classes cháº¯c cháº¯n thuá»™c target "Giá»i"
Target_set = {ID1, ID2}  # CÃ¡c object cÃ³ Káº¿t quáº£ = "Giá»i"
Lower_Approx = {}  # Chá»‰ nhá»¯ng class hoÃ n toÃ n trong target
# Class 1: {ID1} âŠ† {ID1,ID2} â†’ ThÃªm vÃ o Lower
# Class 2: {ID2} âŠ† {ID1,ID2} â†’ ThÃªm vÃ o Lower
Lower_Approx = {ID1, ID2}
```

#### BÆ°á»›c 4: TÃ­nh Upper Approximation

```python
# TÃ¬m classes cÃ³ giao khÃ¡c rá»—ng vá»›i target
Upper_Approx = {}
# Class 1: {ID1} âˆ© {ID1,ID2} â‰  âˆ… â†’ ThÃªm vÃ o Upper
# Class 2: {ID2} âˆ© {ID1,ID2} â‰  âˆ… â†’ ThÃªm vÃ o Upper
Upper_Approx = {ID1, ID2}
```

#### BÆ°á»›c 5: TÃ­nh Accuracy vÃ  Dependency

```python
Accuracy = |Lower_Approx| / |Upper_Approx| = 2/2 = 1.0
Dependency = |Lower_Approx| / |Total_Objects| = 2/4 = 0.5
```

#### BÆ°á»›c 6: TÃ¬m Reducts

```python
# Test tá»«ng subset cá»§a attributes
Full_dependency = dependency([ToÃ¡n,LÃ½,HÃ³a], Káº¿t quáº£) = 0.75
Test: dependency([ToÃ¡n,LÃ½], Káº¿t quáº£) = 0.5 â‰  0.75
Test: dependency([ToÃ¡n,HÃ³a], Káº¿t quáº£) = 0.5 â‰  0.75
Test: dependency([LÃ½,HÃ³a], Káº¿t quáº£) = 0.5 â‰  0.75
â†’ KhÃ´ng cÃ³ reduct, cáº§n táº¥t cáº£ 3 thuá»™c tÃ­nh
```

### Reduct vÃ  Core:

- **Reduct**: Táº­p con tá»‘i thiá»ƒu cá»§a thuá»™c tÃ­nh váº«n giá»¯ nguyÃªn kháº£ nÄƒng phÃ¢n loáº¡i
- **Core**: Giao cá»§a táº¥t cáº£ cÃ¡c reduct (thuá»™c tÃ­nh khÃ´ng thá»ƒ thiáº¿u)

---

# 3. DECISION TREE ID3 - CÃ‚Y QUYáº¾T Äá»ŠNH

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Decision Tree lÃ  gÃ¬?

NhÆ° má»™t cÃ¢y cÃ¢u há»i Ä‘á»ƒ Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh! Má»—i nÃºt lÃ  má»™t cÃ¢u há»i, má»—i nhÃ¡nh lÃ  má»™t Ä‘Ã¡p Ã¡n.

**VÃ­ dá»¥: CÃ³ nÃªn Ä‘i chÆ¡i khÃ´ng?**

```
ğŸŒ¤ï¸ Thá»i tiáº¿t nhÆ° tháº¿ nÃ o?
â”œâ”€â”€ â˜€ï¸ Náº¯ng
â”‚   â””â”€â”€ ğŸ˜Š Äi chÆ¡i!
â”œâ”€â”€ ğŸŒ§ï¸ MÆ°a
â”‚   â””â”€â”€ ğŸ  á» nhÃ 
â””â”€â”€ â˜ï¸ Nhiá»u mÃ¢y
    â””â”€â”€ ğŸ’° CÃ³ tiá»n khÃ´ng?
        â”œâ”€â”€ ğŸ’¸ CÃ³ â†’ ğŸ˜Š Äi chÆ¡i!
        â””â”€â”€ ğŸ’¸ KhÃ´ng â†’ ğŸ  á» nhÃ 
```

### Táº¡i sao dÃ¹ng Decision Tree?

- ğŸ“– **Dá»… hiá»ƒu**: NhÆ° sÃ¡ch hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c
- ğŸš€ **Nhanh**: Quyáº¿t Ä‘á»‹nh trong vÃ i giÃ¢y
- ğŸ¯ **ChÃ­nh xÃ¡c**: Dá»±a trÃªn dá»¯ liá»‡u thá»±c táº¿

### CÃ¡ch hoáº¡t Ä‘á»™ng:

1. **Chá»n cÃ¢u há»i tá»‘t nháº¥t** (thuá»™c tÃ­nh quan trá»ng nháº¥t)
2. **Chia dá»¯ liá»‡u** theo cÃ¢u tráº£ lá»i
3. **Láº·p láº¡i** cho Ä‘áº¿n khi cÃ³ káº¿t quáº£ rÃµ rÃ ng

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n thuá»™c tÃ­nh:

- **Thuá»™c tÃ­nh má»¥c tiÃªu**: Cá»™t cáº§n dá»± Ä‘oÃ¡n (VD: "Buy", "Class", "Result")
- **Thuá»™c tÃ­nh Ä‘áº§u vÃ o**: CÃ¡c cá»™t Ä‘áº·c trÆ°ng (VD: "Age", "Income", "Gender")

### ğŸ“Š PhÆ°Æ¡ng phÃ¡p chia nhÃ¡nh:

1. **Information Gain (Entropy)**

   - Dá»±a trÃªn lÃ½ thuyáº¿t thÃ´ng tin
   - Æ¯u tiÃªn thuá»™c tÃ­nh giáº£m entropy nhiá»u nháº¥t
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u cÃ¢n báº±ng, nhiá»u class

2. **Gini Gain**
   - Dá»±a trÃªn Ä‘á»™ báº¥t thuáº§n Gini
   - Nhanh hÆ¡n entropy
   - **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u lá»›n, cáº§n tá»‘c Ä‘á»™

### ğŸš« LÆ°u Ã½ khi sá»­ dá»¥ng:

- App tá»± Ä‘á»™ng chuyá»ƒn táº¥t cáº£ dá»¯ liá»‡u sang string
- Loáº¡i bá» cÃ¡c dÃ²ng cÃ³ giÃ¡ trá»‹ 'nan'
- Hiá»ƒn thá»‹ Ä‘iá»ƒm sá»‘ cá»§a tá»«ng thuá»™c tÃ­nh trÆ°á»›c khi xÃ¢y dá»±ng cÃ¢y

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Thuáº­t toÃ¡n ID3:

ID3 sá»­ dá»¥ng **Information Gain** Ä‘á»ƒ chá»n thuá»™c tÃ­nh tá»‘t nháº¥t cho má»—i nÃºt.

**Entropy:**

```
Entropy(S) = -âˆ‘(p_i Ã— logâ‚‚(p_i))
```

**Information Gain:**

```
Gain(S,A) = Entropy(S) - âˆ‘((|S_v|/|S|) Ã— Entropy(S_v))
```

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

```
| Age | Income | Gender | Buy |
|-----|--------|--------|-----|
| 25  | 30000  | Male   | Yes |
| 30  | 45000  | Female | Yes |
| 35  | 55000  | Male   | No  |
| 28  | 38000  | Female | Yes |
```

#### BÆ°á»›c 2: TÃ­nh Entropy cá»§a táº­p gá»‘c

```python
Total = 4, Yes = 3, No = 1
Entropy(S) = -[3/4 Ã— logâ‚‚(3/4) + 1/4 Ã— logâ‚‚(1/4)]
           = -[0.75 Ã— (-0.415) + 0.25 Ã— (-2)]
           = 0.811
```

#### BÆ°á»›c 3: TÃ­nh Information Gain cho tá»«ng thuá»™c tÃ­nh

**Thuá»™c tÃ­nh Age:**

```python
# Chia theo Age
Age=25: {Yes} â†’ Entropy = 0
Age=30: {Yes} â†’ Entropy = 0
Age=35: {No} â†’ Entropy = 0
Age=28: {Yes} â†’ Entropy = 0

Gain(Age) = 0.811 - [1/4Ã—0 + 1/4Ã—0 + 1/4Ã—0 + 1/4Ã—0] = 0.811
```

**Thuá»™c tÃ­nh Income:**

```python
# NhÃ³m theo khoáº£ng income
Low(â‰¤35000): {Yes} â†’ Entropy = 0
High(>35000): {Yes,Yes,No} â†’ Entropy = 0.918

Gain(Income) = 0.811 - [1/4Ã—0 + 3/4Ã—0.918] = 0.122
```

#### BÆ°á»›c 4: Chá»n thuá»™c tÃ­nh tá»‘t nháº¥t

```python
Gain(Age) = 0.811 (cao nháº¥t)
Gain(Income) = 0.122
Gain(Gender) = 0.311

â†’ Chá»n Age lÃ m root node
```

#### BÆ°á»›c 5: XÃ¢y dá»±ng cÃ¢y Ä‘á»‡ quy

```
       Age
    â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
   25    30    35    28
    â”‚     â”‚     â”‚     â”‚
   Yes   Yes   No    Yes
```

### Pseudocode:

```python
def ID3(examples, target_attribute, attributes):
    # Base cases
    if all examples have same target value:
        return leaf node with that value

    if attributes is empty:
        return leaf node with majority target value

    # Choose best attribute
    best_attr = argmax(information_gain(examples, attr, target))

    # Create decision node
    tree = DecisionNode(best_attr)

    # Recursively build subtrees
    for value in values(best_attr):
        subset = examples where best_attr = value
        if subset is empty:
            add leaf with majority value
        else:
            remaining_attrs = attributes - {best_attr}
            subtree = ID3(subset, target_attribute, remaining_attrs)
            tree.add_branch(value, subtree)

    return tree
```

### Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm:

**Æ¯u Ä‘iá»ƒm:**

- Dá»… hiá»ƒu vÃ  giáº£i thÃ­ch
- KhÃ´ng cáº§n giáº£ Ä‘á»‹nh vá» phÃ¢n phá»‘i dá»¯ liá»‡u
- Xá»­ lÃ½ Ä‘Æ°á»£c dá»¯ liá»‡u categorical

**NhÆ°á»£c Ä‘iá»ƒm:**

- Dá»… overfitting
- ThiÃªn vá»‹ vá»›i thuá»™c tÃ­nh cÃ³ nhiá»u giÃ¡ trá»‹
- KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c dá»¯ liá»‡u thiáº¿u

---

# 4. NAIVE BAYES - PHÃ‚N LOáº I XÃC SUáº¤T

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### Naive Bayes lÃ  gÃ¬?

NhÆ° má»™t bÃ¡c sÄ© cháº©n Ä‘oÃ¡n bá»‡nh dá»±a trÃªn triá»‡u chá»©ng!

**VÃ­ dá»¥: PhÃ¢n loáº¡i email spam**

```
ğŸ“§ Email cÃ³ tá»« "FREE" â†’ 80% lÃ  spam
ğŸ“§ Email cÃ³ tá»« "MONEY" â†’ 70% lÃ  spam
ğŸ“§ Email cÃ³ tá»« "URGENT" â†’ 60% lÃ  spam

ğŸ“© Email má»›i: "FREE MONEY URGENT!!!"
â†’ XÃ¡c suáº¥t spam ráº¥t cao!
```

### Táº¡i sao gá»i lÃ  "Naive" (NgÃ¢y thÆ¡)?

VÃ¬ thuáº­t toÃ¡n **giáº£ Ä‘á»‹nh** cÃ¡c Ä‘áº·c trÆ°ng Ä‘á»™c láº­p vá»›i nhau (Ä‘iá»u nÃ y thÆ°á»ng khÃ´ng Ä‘Ãºng trong thá»±c táº¿).

**VÃ­ dá»¥ ngÃ¢y thÆ¡:**

- Giáº£ Ä‘á»‹nh: Tá»« "FREE" vÃ  "MONEY" xuáº¥t hiá»‡n Ä‘á»™c láº­p
- Thá»±c táº¿: Spam thÆ°á»ng dÃ¹ng cáº£ hai tá»« cÃ¹ng lÃºc

### CÃ¡c loáº¡i Naive Bayes:

- **Gaussian NB**: Cho dá»¯ liá»‡u sá»‘ (chiá»u cao, cÃ¢n náº·ng...)
- **Multinomial NB**: Cho dá»¯ liá»‡u Ä‘áº¿m (sá»‘ tá»« trong email...)

## âš™ï¸ CÃC TÃ™YY CHá»ŒN TRONG APP

### ğŸ¯ Chá»n cá»™t má»¥c tiÃªu:

- Chá»n tá»« sidebar trÆ°á»›c khi cháº¡y thuáº­t toÃ¡n
- **LÆ°u Ã½**: Báº¯t buá»™c pháº£i chá»n cho Naive Bayes

### ğŸ”§ TÃ¹y chá»n loáº¡i Naive Bayes:

#### 1. **GaussianNB**

- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u sá»‘ liÃªn tá»¥c (tuá»•i, lÆ°Æ¡ng, Ä‘iá»ƒm sá»‘...)
- **Giáº£ Ä‘á»‹nh**: Features tuÃ¢n theo phÃ¢n phá»‘i Gaussian (normal)
- **Æ¯u Ä‘iá»ƒm**: KhÃ´ng cáº§n tham sá»‘, tá»± Ä‘á»™ng tÃ­nh mean vÃ  variance
- **NhÆ°á»£c Ä‘iá»ƒm**: Giáº£ Ä‘á»‹nh phÃ¢n phá»‘i cÃ³ thá»ƒ khÃ´ng Ä‘Ãºng

#### 2. **MultinomialNB**

- **Khi nÃ o dÃ¹ng**: Dá»¯ liá»‡u Ä‘áº¿m, frequency (text classification, word count...)
- **Tham sá»‘ Alpha**: Laplace smoothing (0.01-3.0, thÆ°á»ng 0.5-1.0)
  - Alpha tháº¥p: Ãt smoothing, cÃ³ thá»ƒ overfitting
  - Alpha cao: Nhiá»u smoothing, cÃ³ thá»ƒ underfitting
- **YÃªu cáº§u**: Táº¥t cáº£ features â‰¥ 0
- **Xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m**: TÃ­ch chá»n "Ãp dá»¥ng MinMaxScaler"

### ğŸ“Š Káº¿t quáº£ hiá»ƒn thá»‹:

- **Training Accuracy**: Äá»™ chÃ­nh xÃ¡c trÃªn táº­p huáº¥n luyá»‡n
- **Model Type**: Loáº¡i model Ä‘Ã£ train
- **Feature Info**: ThÃ´ng tin vá» features Ä‘Ã£ xá»­ lÃ½

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Äá»‹nh lÃ½ Bayes:

```
P(C|X) = P(X|C) Ã— P(C) / P(X)
```

Trong Ä‘Ã³:

- P(C|X): XÃ¡c suáº¥t thuá»™c class C khi biáº¿t features X
- P(X|C): Likelihood - xÃ¡c suáº¥t cÃ³ features X khi thuá»™c class C
- P(C): Prior - xÃ¡c suáº¥t ban Ä‘áº§u cá»§a class C
- P(X): Evidence - xÃ¡c suáº¥t cÃ³ features X

### Giáº£ Ä‘á»‹nh Ä‘á»™c láº­p:

```
P(xâ‚,xâ‚‚,...,xâ‚™|C) = P(xâ‚|C) Ã— P(xâ‚‚|C) Ã— ... Ã— P(xâ‚™|C)
```

### CÃ´ng thá»©c tá»•ng quÃ¡t:

```
Ä‰ = argmax P(c) âˆ P(xáµ¢|c)
    câˆˆC         i=1
```

### CÃ¡c biáº¿n thá»ƒ:

**Gaussian Naive Bayes:**

```
P(xáµ¢|c) = (1/âˆš(2Ï€ÏƒÂ²c)) Ã— exp(-(xáµ¢-Î¼c)Â²/(2ÏƒÂ²c))
```

**Multinomial Naive Bayes:**

```
P(xáµ¢|c) = (Náµ¢c + Î±) / (Nc + Î±|V|)
```

---

# 5. K-MEANS - PHÃ‚N Cá»¤M

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### K-Means lÃ  gÃ¬?

NhÆ° viá»‡c chia há»c sinh thÃ nh cÃ¡c nhÃ³m dá»±a trÃªn Ä‘iá»ƒm sá»‘!

**VÃ­ dá»¥: Chia khÃ¡ch hÃ ng thÃ nh 3 nhÃ³m**

```
ğŸ‘¥ NhÃ³m 1: KhÃ¡ch hÃ ng VIP (thu nháº­p cao, mua nhiá»u)
ğŸ‘¥ NhÃ³m 2: KhÃ¡ch hÃ ng thÆ°á»ng (thu nháº­p trung bÃ¬nh)
ğŸ‘¥ NhÃ³m 3: KhÃ¡ch hÃ ng má»›i (thu nháº­p tháº¥p, Ã­t mua)
```

### CÃ¡ch hoáº¡t Ä‘á»™ng (nhÆ° chÆ¡i game):

1. **ğŸ¯ Äáº·t K tÃ¢m cá»¥m ngáº«u nhiÃªn** (K = 3 tÃ¢m)
2. **ğŸ‘¥ GÃ¡n má»—i ngÆ°á»i vÃ o nhÃ³m gáº§n nháº¥t**
3. **ğŸ“ Di chuyá»ƒn tÃ¢m vá» giá»¯a nhÃ³m**
4. **ğŸ”„ Láº·p láº¡i** cho Ä‘áº¿n khi á»•n Ä‘á»‹nh

### Minh há»a trá»±c quan:

```
BÆ°á»›c 1: TÃ¢m ngáº«u nhiÃªn        BÆ°á»›c 2: GÃ¡n nhÃ³m
   *     â€¢  â€¢                   *â—â—   â—‹ â—‹
 â€¢   â€¢     â€¢                  â—   â—   â—‹ â—‹
   â€¢   *     â€¢ â€¢                â—   *â—‹   â—‹ â—‹
     â€¢   â€¢  *                    â—   â—‹â—‹  *â—‹

BÆ°á»›c 3: Di chuyá»ƒn tÃ¢m          Káº¿t quáº£ cuá»‘i:
   *â—â—   â—‹ â—‹                    *â—â—   â—‹ â—‹
 â—   â—   â—‹ â—‹                  â—   â—   â—‹ â—‹
   â—   *â—‹   â—‹ â—‹                 â—   *â—‹   â—‹ â—‹
     â—   â—‹â—‹  *â—‹                   â—   â—‹â—‹  *â—‹
```

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Objective Function:

K-Means tá»‘i thiá»ƒu hÃ³a **Within-Cluster Sum of Squares (WCSS)**:

```
J = âˆ‘âˆ‘ ||xáµ¢ - Î¼â±¼||Â²
    j=1 iâˆˆCâ±¼
```

### Thuáº­t toÃ¡n Lloyd:

```python
def kmeans(X, k, max_iters=100):
    # Initialize centroids randomly
    centroids = initialize_random(X, k)

    for iteration in range(max_iters):
        # Assignment step
        clusters = assign_points_to_centroids(X, centroids)

        # Update step
        new_centroids = compute_centroids(clusters)

        # Check convergence
        if converged(centroids, new_centroids):
            break

        centroids = new_centroids

    return clusters, centroids
```

### Äá»™ phá»©c táº¡p:

- **Time**: O(n Ã— k Ã— i Ã— d)
  - n: sá»‘ Ä‘iá»ƒm dá»¯ liá»‡u
  - k: sá»‘ cá»¥m
  - i: sá»‘ iteration
  - d: sá»‘ chiá»u

### ğŸ“‹ CÃC BÆ¯á»šC GIáº¢I QUYáº¾T CHI TIáº¾T:

#### BÆ°á»›c 1: Chuáº©n bá»‹ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u

```python
# Dá»¯ liá»‡u gá»‘c
data = [[25, 30000], [30, 45000], [35, 55000], [22, 25000]]

# Chuáº©n hÃ³a báº±ng MinMaxScaler
scaled_data = [[0.0, 0.0], [0.38, 0.67], [1.0, 1.0], [0.0, 0.0]]
```

#### BÆ°á»›c 2: Khá»Ÿi táº¡o K centroids ngáº«u nhiÃªn

```python
K = 3
centroids = [[0.2, 0.3], [0.6, 0.8], [0.9, 0.1]]  # Random positions
```

#### BÆ°á»›c 3: Assignment Step

```python
# TÃ­nh khoáº£ng cÃ¡ch tá»« má»—i Ä‘iá»ƒm Ä‘áº¿n centroids
for each point:
    distances = [euclidean(point, centroid) for centroid in centroids]
    assign point to closest centroid

# Káº¿t quáº£ iteration 1:
Cluster 0: [point1, point4]
Cluster 1: [point2]
Cluster 2: [point3]
```

#### BÆ°á»›c 4: Update Step

```python
# TÃ­nh centroid má»›i = trung bÃ¬nh cá»§a cÃ¡c Ä‘iá»ƒm trong cluster
new_centroids = []
for cluster in clusters:
    new_centroid = mean(cluster_points)
    new_centroids.append(new_centroid)

# New centroids: [[0.1, 0.1], [0.38, 0.67], [1.0, 1.0]]
```

#### BÆ°á»›c 5: Kiá»ƒm tra há»™i tá»¥

```python
# Náº¿u centroids khÃ´ng thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ â†’ Dá»«ng
# NgÆ°á»£c láº¡i â†’ Láº·p láº¡i BÆ°á»›c 3 vÃ  4

convergence_threshold = 0.001
if max(distance(old_centroid, new_centroid)) < threshold:
    break
```

#### BÆ°á»›c 6: TÃ­nh WCSS (Within-Cluster Sum of Squares)

```python
wcss = 0
for cluster in clusters:
    for point in cluster:
        wcss += euclidean_distance(point, cluster_centroid)**2
```

### CÃ¡ch chá»n K:

1. **Elbow Method**: TÃ¬m "khuá»·u tay" trÃªn Ä‘á»“ thá»‹ WCSS

   ```python
   # Cháº¡y K-Means vá»›i K = 1,2,3,4,5...
   # Plot WCSS vs K
   # Chá»n K táº¡i Ä‘iá»ƒm "elbow" (giáº£m cháº­m láº¡i)
   ```

2. **Silhouette Analysis**: Äo Ä‘á»™ tÃ¡ch biá»‡t cá»§a cÃ¡c cá»¥m

   ```python
   # Silhouette score tá»« -1 Ä‘áº¿n 1
   # Score cao = clusters tÃ¡ch biá»‡t tá»‘t
   # Chá»n K cÃ³ silhouette score cao nháº¥t
   ```

3. **Gap Statistic**: So sÃ¡nh vá»›i phÃ¢n phá»‘i ngáº«u nhiÃªn
   ```python
   # So sÃ¡nh WCSS thá»±c táº¿ vs WCSS cá»§a dá»¯ liá»‡u random
   # Chá»n K cÃ³ gap lá»›n nháº¥t
   ```

---

# 6. KOHONEN SOM - Báº¢N Äá»’ Tá»° Tá»” CHá»¨C

## ğŸŒŸ PhiÃªn báº£n Dá»„ HIá»‚U

### SOM lÃ  gÃ¬?

NhÆ° viá»‡c váº½ báº£n Ä‘á»“ tháº¿ giá»›i trÃªn giáº¥y pháº³ng! Biáº¿n dá»¯ liá»‡u phá»©c táº¡p nhiá»u chiá»u thÃ nh báº£n Ä‘á»“ 2D dá»… nhÃ¬n.

**VÃ­ dá»¥ thá»±c táº¿:**

```
ğŸµ PhÃ¢n loáº¡i nháº¡c:
- GÃ³c trÃªn trÃ¡i: Rock, Metal
- GÃ³c trÃªn pháº£i: Classical, Jazz
- GÃ³c dÆ°á»›i trÃ¡i: Pop, Dance
- GÃ³c dÆ°á»›i pháº£i: Country, Folk

â†’ Nháº¡c tÆ°Æ¡ng tá»± sáº½ á»Ÿ gáº§n nhau trÃªn báº£n Ä‘á»“!
```

### Táº¡i sao há»¯u Ã­ch?

- ğŸ‘ï¸ **Trá»±c quan hÃ³a**: Tháº¥y Ä‘Æ°á»£c pattern trong dá»¯ liá»‡u
- ğŸ—ºï¸ **Giáº£m chiá»u**: Tá»« 100 thuá»™c tÃ­nh â†’ báº£n Ä‘á»“ 2D
- ğŸ” **TÃ¬m nhÃ³m**: CÃ¡c vÃ¹ng tÆ°Æ¡ng tá»± nhau

### CÃ¡ch hoáº¡t Ä‘á»™ng (nhÆ° há»c báº£n Ä‘á»“):

1. **ğŸ—ºï¸ Táº¡o lÆ°á»›i trá»‘ng** (nhÆ° báº£n Ä‘á»“ tráº¯ng)
2. **ğŸ“ Äáº·t dá»¯ liá»‡u lÃªn lÆ°á»›i** (má»—i Ä‘iá»ƒm tÃ¬m vá»‹ trÃ­ phÃ¹ há»£p)
3. **ğŸ”„ Äiá»u chá»‰nh dáº§n** (vÃ¹ng xung quanh cÅ©ng thay Ä‘á»•i)
4. **âœ… HoÃ n thÃ nh báº£n Ä‘á»“** (dá»¯ liá»‡u tÆ°Æ¡ng tá»± á»Ÿ gáº§n nhau)

## ğŸ”¬ PhiÃªn báº£n TECHNICAL

### Cáº¥u trÃºc SOM:

- **Input Layer**: Vector Ä‘áº§u vÃ o x âˆˆ â„â¿
- **Output Layer**: LÆ°á»›i 2D cÃ¡c neuron vá»›i weight vector wáµ¢â±¼ âˆˆ â„â¿

### Thuáº­t toÃ¡n training:

**1. TÃ¬m Best Matching Unit (BMU):**

```
c = argmin ||x(t) - wáµ¢â±¼(t)||
    i,j
```

**2. Update weights:**

```
wáµ¢â±¼(t+1) = wáµ¢â±¼(t) + Î±(t) Ã— h(c,i,j,t) Ã— [x(t) - wáµ¢â±¼(t)]
```

**3. Neighborhood function:**

```
h(c,i,j,t) = exp(-||rc - ráµ¢â±¼||Â² / (2Ïƒ(t)Â²))
```

**4. Learning rate decay:**

```
Î±(t) = Î±â‚€ Ã— exp(-t/Ï„â‚)
Ïƒ(t) = Ïƒâ‚€ Ã— exp(-t/Ï„â‚‚)
```

### Pseudocode:

```python
def train_som(data, map_size, epochs):
    # Initialize weight vectors randomly
    weights = initialize_weights(map_size, input_dim)

    for epoch in range(epochs):
        for x in data:
            # Find BMU
            bmu = find_best_matching_unit(x, weights)

            # Update weights in neighborhood
            for i, j in map_coordinates:
                distance = euclidean_distance(bmu, (i,j))
                if distance <= neighborhood_radius(epoch):
                    influence = neighborhood_function(distance, epoch)
                    learning_rate = get_learning_rate(epoch)

                    weights[i][j] += learning_rate * influence * (x - weights[i][j])

    return weights
```

---

# ğŸ“Š SO SÃNH CÃC THUáº¬T TOÃN

| Thuáº­t toÃ¡n        | Loáº¡i           | á»¨ng dá»¥ng chÃ­nh        | Æ¯u Ä‘iá»ƒm           | NhÆ°á»£c Ä‘iá»ƒm           |
| ----------------- | -------------- | --------------------- | ----------------- | -------------------- |
| **Apriori**       | Association    | Basket Analysis       | TÃ¬m pattern áº©n    | Cháº­m vá»›i dá»¯ liá»‡u lá»›n |
| **Rough Set**     | Classification | Feature Selection     | Xá»­ lÃ½ uncertainty | Phá»©c táº¡p tÃ­nh toÃ¡n   |
| **Decision Tree** | Classification | Rule Extraction       | Dá»… hiá»ƒu           | Dá»… overfitting       |
| **Naive Bayes**   | Classification | Text Classification   | Nhanh, Ä‘Æ¡n giáº£n   | Giáº£ Ä‘á»‹nh Ä‘á»™c láº­p     |
| **K-Means**       | Clustering     | Customer Segmentation | ÄÆ¡n giáº£n, nhanh   | Cáº§n biáº¿t trÆ°á»›c K     |
| **SOM**           | Visualization  | Data Exploration      | Trá»±c quan hÃ³a tá»‘t | KhÃ³ diá»…n giáº£i        |

---

# ğŸ¯ Káº¾T LUáº¬N

Má»—i thuáº­t toÃ¡n cÃ³ Ä‘iá»ƒm máº¡nh riÃªng:

- **ğŸ›’ Muá»‘n tÃ¬m pattern mua hÃ ng** â†’ DÃ¹ng **Apriori**
- **ğŸ¯ Muá»‘n phÃ¢n loáº¡i chÃ­nh xÃ¡c** â†’ DÃ¹ng **Decision Tree** hoáº·c **Naive Bayes**
- **ğŸ‘¥ Muá»‘n chia nhÃ³m khÃ¡ch hÃ ng** â†’ DÃ¹ng **K-Means**
- **ğŸ—ºï¸ Muá»‘n khÃ¡m phÃ¡ dá»¯ liá»‡u** â†’ DÃ¹ng **SOM**
- **âš–ï¸ Muá»‘n loáº¡i bá» thuá»™c tÃ­nh thá»«a** â†’ DÃ¹ng **Rough Set**

**Lá»i khuyÃªn:** HÃ£y thá»­ nhiá»u thuáº­t toÃ¡n vÃ  so sÃ¡nh káº¿t quáº£ Ä‘á»ƒ chá»n phÆ°Æ¡ng phÃ¡p phÃ¹ há»£p nháº¥t!

---

# 7. HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG APP

## ğŸš€ Khá»Ÿi cháº¡y á»©ng dá»¥ng

### CÃ¡ch 1: Sá»­ dá»¥ng file batch (Windows)

```bash
# Double-click file run_demo.bat
# Hoáº·c cháº¡y trong command prompt:
run_demo.bat
```

### CÃ¡ch 2: Sá»­ dá»¥ng terminal

```bash
# CÃ i Ä‘áº·t dependencies (chá»‰ cáº§n lÃ m 1 láº§n)
pip install streamlit pandas numpy matplotlib seaborn scikit-learn mlxtend minisom graphviz

# Cháº¡y app
streamlit run app.py
```

## ğŸ“Š Quy trÃ¬nh sá»­ dá»¥ng tá»«ng thuáº­t toÃ¡n

### 1ï¸âƒ£ **APRIORI - Luáº­t káº¿t há»£p**

#### BÆ°á»›c 1: Upload dá»¯ liá»‡u

- Táº£i file CSV cÃ³ dá»¯ liá»‡u giao dá»‹ch
- VD: Cá»™t "TransactionID" vÃ  "Product"

#### BÆ°á»›c 2: Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½

```
ğŸ”¹ One-hot encode: Cho dá»¯ liá»‡u giao dá»‹ch chuáº©n
   - Chá»n 2 cá»™t: [TransactionID, Product]

ğŸ”¹ Dá»¯ liá»‡u sá»‘ gá»‘c: Cho dá»¯ liá»‡u Ä‘Ã£ á»Ÿ dáº¡ng 0/1

ğŸ”¹ Chuyá»ƒn boolean: Cho dá»¯ liá»‡u há»—n há»£p
```

#### BÆ°á»›c 3: Thiáº¿t láº­p tham sá»‘

- **Support**: 0.1-0.5 (thÆ°á»ng dÃ¹ng 0.3)
- **Confidence**: 0.5-0.8 (thÆ°á»ng dÃ¹ng 0.6)

#### BÆ°á»›c 4: PhÃ¢n tÃ­ch káº¿t quáº£

```
âœ… Táº­p phá»• biáº¿n: CÃ¡c item xuáº¥t hiá»‡n thÆ°á»ng xuyÃªn
âœ… Táº­p tá»‘i Ä‘áº¡i: Táº­p phá»• biáº¿n khÃ´ng chá»©a trong táº­p nÃ o lá»›n hÆ¡n
âœ… Luáº­t káº¿t há»£p: If A then B vá»›i confidence
```

---

### 2ï¸âƒ£ **ROUGH SET - Táº­p thÃ´**

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

- Äáº£m báº£o cÃ³ cá»™t káº¿t quáº£ rÃµ rÃ ng
- Dá»¯ liá»‡u categorical hoáº·c Ä‘Ã£ rá»i ráº¡c hÃ³a

#### BÆ°á»›c 2: Chá»n thuá»™c tÃ­nh

```
ğŸ¯ Thuá»™c tÃ­nh quyáº¿t Ä‘á»‹nh: Cá»™t káº¿t quáº£ (VD: "Buy")
ğŸ“Š Thuá»™c tÃ­nh Ä‘iá»u kiá»‡n: CÃ¡c cá»™t Ä‘áº·c trÆ°ng (VD: "Age", "Income")
```

#### BÆ°á»›c 3: Chá»n lá»›p má»¥c tiÃªu

- Chá»n giÃ¡ trá»‹ cá»¥ thá»ƒ cáº§n phÃ¢n tÃ­ch (VD: "Yes")

#### BÆ°á»›c 4: Äá»c káº¿t quáº£

```
ğŸ“ Xáº¥p xá»‰ dÆ°á»›i: Cháº¯c cháº¯n thuá»™c lá»›p
ğŸ“ Xáº¥p xá»‰ trÃªn: CÃ³ thá»ƒ thuá»™c lá»›p
ğŸ“Š Äá»™ chÃ­nh xÃ¡c: Tá»· lá»‡ dÆ°á»›i/trÃªn
ğŸ”§ RÃºt gá»n: Thuá»™c tÃ­nh tá»‘i thiá»ƒu cáº§n thiáº¿t
```

---

### 3ï¸âƒ£ **DECISION TREE - CÃ¢y quyáº¿t Ä‘á»‹nh**

#### BÆ°á»›c 1: Chá»n thuá»™c tÃ­nh

```
ğŸ¯ Thuá»™c tÃ­nh má»¥c tiÃªu: Cá»™t cáº§n dá»± Ä‘oÃ¡n
ğŸ“Š Thuá»™c tÃ­nh Ä‘áº§u vÃ o: CÃ¡c cá»™t Ä‘áº·c trÆ°ng
```

#### BÆ°á»›c 2: Chá»n phÆ°Æ¡ng phÃ¡p

- **Gain (Entropy)**: Cho dá»¯ liá»‡u cÃ¢n báº±ng
- **Gini Gain**: Cho dá»¯ liá»‡u lá»›n, cáº§n tá»‘c Ä‘á»™

#### BÆ°á»›c 3: PhÃ¢n tÃ­ch káº¿t quáº£

```
ğŸŒ³ Biá»ƒu Ä‘á»“ cÃ¢y: Visualization dá»… hiá»ƒu
ğŸ“‹ Luáº­t rÃºt ra: Dáº¡ng IF-THEN
ğŸ“Š Äiá»ƒm thuá»™c tÃ­nh: Information Gain/Gini cá»§a tá»«ng feature
```

---

### 4ï¸âƒ£ **NAIVE BAYES - PhÃ¢n loáº¡i xÃ¡c suáº¥t**

#### BÆ°á»›c 1: Chá»n cá»™t má»¥c tiÃªu

- Chá»n cá»™t cáº§n phÃ¢n loáº¡i tá»« sidebar

#### BÆ°á»›c 2: Chá»n loáº¡i Naive Bayes

```
ğŸ”¹ GaussianNB: Cho dá»¯ liá»‡u sá»‘ liÃªn tá»¥c
ğŸ”¹ MultinomialNB: Cho dá»¯ liá»‡u Ä‘áº¿m/frequency
   - CÃ i Ä‘áº·t Alpha (Laplace smoothing): 0.1-3.0
   - CÃ³ thá»ƒ cáº§n MinMaxScaler náº¿u cÃ³ giÃ¡ trá»‹ Ã¢m
```

#### BÆ°á»›c 3: Äá»c káº¿t quáº£

```
ğŸ“Š Accuracy: Äá»™ chÃ­nh xÃ¡c trÃªn táº­p training
âš¡ Tá»‘c Ä‘á»™: Ráº¥t nhanh, phÃ¹ há»£p dá»¯ liá»‡u lá»›n
```

---

### 5ï¸âƒ£ **K-MEANS - PhÃ¢n cá»¥m**

#### BÆ°á»›c 1: Chuáº©n bá»‹ dá»¯ liá»‡u

- KhÃ´ng cáº§n chá»n cá»™t má»¥c tiÃªu
- Sá»­ dá»¥ng táº¥t cáº£ cá»™t sá»‘

#### BÆ°á»›c 2: Chá»n sá»‘ cá»¥m K

- ThÆ°á»ng chá»n 2-5 cá»¥m
- CÃ³ thá»ƒ thá»­ nhiá»u giÃ¡ trá»‹ Ä‘á»ƒ so sÃ¡nh

#### BÆ°á»›c 3: PhÃ¢n tÃ­ch káº¿t quáº£

```
ğŸ“Š Báº£ng gÃ¡n cá»¥m: Má»—i dÃ²ng thuá»™c cá»¥m nÃ o
ğŸ“ˆ Scatter plot: Visualization 2D (náº¿u â‰¥2 thuá»™c tÃ­nh)
ğŸ¯ TÃ¢m cá»¥m: Vá»‹ trÃ­ trung tÃ¢m cá»§a tá»«ng cá»¥m
```

---

### 6ï¸âƒ£ **KOHONEN SOM - Báº£n Ä‘á»“ tá»± tá»• chá»©c**

#### BÆ°á»›c 1: Thiáº¿t láº­p tham sá»‘

```
ğŸ”§ KÃ­ch thÆ°á»›c lÆ°á»›i:
   - Rows: 3-10 (thÆ°á»ng 4)
   - Cols: 3-10 (thÆ°á»ng 4)

ğŸšï¸ Tham sá»‘ training:
   - Sigma: 0.5-2.0 (thÆ°á»ng 1.0)
   - Learning Rate: 0.1-0.8 (thÆ°á»ng 0.5)
   - Iterations: 100-1000 (thÆ°á»ng 500)
```

#### BÆ°á»›c 2: Äá»c káº¿t quáº£

```
ğŸ—ºï¸ Hit Map: MÃ u Ä‘áº­m = nhiá»u data points
ğŸ“Š Class Maps: PhÃ¢n bá»‘ tá»«ng lá»›p trÃªn báº£n Ä‘á»“
ğŸ” Pattern: VÃ¹ng tÆ°Æ¡ng tá»± gáº§n nhau
```

## ğŸ¯ TIPS Sá»¬ Dá»¤NG HIá»†U QUáº¢

### âœ… NÃªn lÃ m:

- **Test nhiá»u tham sá»‘**: Thá»­ cÃ¡c giÃ¡ trá»‹ khÃ¡c nhau Ä‘á»ƒ so sÃ¡nh
- **Chuáº©n bá»‹ dá»¯ liá»‡u tá»‘t**: Clean data trÆ°á»›c khi upload
- **Äá»c cáº£nh bÃ¡o**: App cÃ³ thÃ´ng bÃ¡o há»¯u Ã­ch
- **So sÃ¡nh thuáº­t toÃ¡n**: DÃ¹ng nhiá»u phÆ°Æ¡ng phÃ¡p cho cÃ¹ng bÃ i toÃ¡n

### âŒ TrÃ¡nh:

- **Dá»¯ liá»‡u quÃ¡ Ã­t**: <10 dÃ²ng sáº½ khÃ³ phÃ¢n tÃ­ch
- **QuÃ¡ nhiá»u thuá»™c tÃ­nh**: CÃ³ thá»ƒ gÃ¢y overfitting
- **Tham sá»‘ cá»±c Ä‘oan**: Min support = 0.01 hoáº·c 0.99
- **Bá» qua validation**: KhÃ´ng check káº¿t quáº£ cÃ³ há»£p lÃ½

### ğŸ”§ Xá»­ lÃ½ lá»—i thÆ°á»ng gáº·p:

**Lá»—i: "File seems to be binary"**

- Upload file CSV, khÃ´ng pháº£i Excel/Word

**Lá»—i: "MultinomialNB khÃ´ng thá»ƒ xá»­ lÃ½ giÃ¡ trá»‹ Ã¢m"**

- TÃ­ch chá»n "Ãp dá»¥ng MinMaxScaler"

**Cáº£nh bÃ¡o: "Cá»™t cÃ³ nhiá»u giÃ¡ trá»‹ duy nháº¥t"**

- CÃ¢n nháº¯c rá»i ráº¡c hÃ³a cho Rough Set

**KhÃ´ng cÃ³ káº¿t quáº£ Apriori**

- Giáº£m min_support xuá»‘ng 0.1-0.2

---

## ğŸ“‹ CHECKLIST TRÆ¯á»šC KHI Sá»¬ Dá»¤NG

- [ ] ÄÃ£ cÃ i Ä‘áº·t Python vÃ  pip
- [ ] ÄÃ£ install cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
- [ ] File dá»¯ liá»‡u á»Ÿ Ä‘á»‹nh dáº¡ng CSV
- [ ] Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch (khÃ´ng quÃ¡ nhiá»u missing values)
- [ ] Hiá»ƒu rÃµ má»¥c tiÃªu phÃ¢n tÃ­ch
- [ ] Äá»c ká»¹ hÆ°á»›ng dáº«n thuáº­t toÃ¡n tÆ°Æ¡ng á»©ng

---

_ğŸ“š TÃ i liá»‡u nÃ y Ä‘Æ°á»£c táº¡o Ä‘á»ƒ há»— trá»£ há»c táº­p mÃ´n Khai thÃ¡c Dá»¯ liá»‡u. ChÃºc báº¡n há»c tá»‘t! ğŸš€_
